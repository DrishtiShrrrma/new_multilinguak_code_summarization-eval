{
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python",
      "version": "3.11.11",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kaggle": {
      "accelerator": "gpu",
      "dataSources": [],
      "dockerImageVersionId": 31041,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": true
    },
    "colab": {
      "provenance": [],
      "gpuType": "A100"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "b71f17e016b243ddb7e051413279a0a3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "VBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_66e54ef4662e4aedbe86ef391ee044c2",
              "IPY_MODEL_8d9867b997e94591971ce3cb0133bdff",
              "IPY_MODEL_5bc2e9d941f24a1f968da3a93dbd8e48",
              "IPY_MODEL_a98723c6c93d4f78943f9da957171b1c",
              "IPY_MODEL_e1df9beca72d4136a5fd23a5cd5f4fd4"
            ],
            "layout": "IPY_MODEL_9383b71bad0c4708b6af4fa98acbc436"
          }
        },
        "66e54ef4662e4aedbe86ef391ee044c2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_54b05ea1869b4d498241719ace739158",
            "placeholder": "​",
            "style": "IPY_MODEL_02bf4b545bc34af58080d544ee15d7ca",
            "value": "<center> <img\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.svg\nalt='Hugging Face'> <br> Copy a token from <a\nhref=\"https://huggingface.co/settings/tokens\" target=\"_blank\">your Hugging Face\ntokens page</a> and paste it below. <br> Immediately click login after copying\nyour token or it might be stored in plain text in this notebook file. </center>"
          }
        },
        "8d9867b997e94591971ce3cb0133bdff": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "PasswordModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "PasswordModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "PasswordView",
            "continuous_update": true,
            "description": "Token:",
            "description_tooltip": null,
            "disabled": false,
            "layout": "IPY_MODEL_bd6fec188d7841b68bf9770ca2293263",
            "placeholder": "​",
            "style": "IPY_MODEL_4193e249864f47e693812757b19cb9d9",
            "value": ""
          }
        },
        "5bc2e9d941f24a1f968da3a93dbd8e48": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "CheckboxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "CheckboxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "CheckboxView",
            "description": "Add token as git credential?",
            "description_tooltip": null,
            "disabled": false,
            "indent": true,
            "layout": "IPY_MODEL_11f7dbf5c03b41598d3f2f4cbc85d684",
            "style": "IPY_MODEL_34a60250e7ca4c2a83d0627cdebe4048",
            "value": true
          }
        },
        "a98723c6c93d4f78943f9da957171b1c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ButtonView",
            "button_style": "",
            "description": "Login",
            "disabled": false,
            "icon": "",
            "layout": "IPY_MODEL_15202594c29b4a5481a3f0f2764226d1",
            "style": "IPY_MODEL_306a8b09209f43a399dd0939b5dc6302",
            "tooltip": ""
          }
        },
        "e1df9beca72d4136a5fd23a5cd5f4fd4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cebfed054acc48729a65d235b3adf1d2",
            "placeholder": "​",
            "style": "IPY_MODEL_41055e6c3ed7496085d19aa7464e5744",
            "value": "\n<b>Pro Tip:</b> If you don't already have one, you can create a dedicated\n'notebooks' token with 'write' access, that you can then easily reuse for all\nnotebooks. </center>"
          }
        },
        "9383b71bad0c4708b6af4fa98acbc436": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": "center",
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": "flex",
            "flex": null,
            "flex_flow": "column",
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "50%"
          }
        },
        "54b05ea1869b4d498241719ace739158": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "02bf4b545bc34af58080d544ee15d7ca": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "bd6fec188d7841b68bf9770ca2293263": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4193e249864f47e693812757b19cb9d9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "11f7dbf5c03b41598d3f2f4cbc85d684": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "34a60250e7ca4c2a83d0627cdebe4048": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "15202594c29b4a5481a3f0f2764226d1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "306a8b09209f43a399dd0939b5dc6302": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "button_color": null,
            "font_weight": ""
          }
        },
        "cebfed054acc48729a65d235b3adf1d2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "41055e6c3ed7496085d19aa7464e5744": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "95a0852a3d4f426b93eadeeaed57b0b2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_5b417f6a252f4a3e894518561f672a11",
              "IPY_MODEL_18413d2d09904f4bb277b52a64448df0",
              "IPY_MODEL_a94dcc96b31b48ceaed8fa9d9099b901"
            ],
            "layout": "IPY_MODEL_27d1ecdd32f6414a9f4c1b173fbc0673"
          }
        },
        "5b417f6a252f4a3e894518561f672a11": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3fd0f11b86d649dc860fe93498828872",
            "placeholder": "​",
            "style": "IPY_MODEL_c5d58718f334432b9ffd3d018e65fbf0",
            "value": "Loading checkpoint shards: 100%"
          }
        },
        "18413d2d09904f4bb277b52a64448df0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ab134d6402a640bfbd6fbbc5fcdeb4e6",
            "max": 5,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_c2a330d5c5f6427eb8f7e86a7a98ca18",
            "value": 5
          }
        },
        "a94dcc96b31b48ceaed8fa9d9099b901": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_321dd4ea701b45fb934a56fad4fcc713",
            "placeholder": "​",
            "style": "IPY_MODEL_33ee379e8239454f8d1223f76d4ef007",
            "value": " 5/5 [00:06&lt;00:00,  1.14s/it]"
          }
        },
        "27d1ecdd32f6414a9f4c1b173fbc0673": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3fd0f11b86d649dc860fe93498828872": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c5d58718f334432b9ffd3d018e65fbf0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ab134d6402a640bfbd6fbbc5fcdeb4e6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c2a330d5c5f6427eb8f7e86a7a98ca18": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "321dd4ea701b45fb934a56fad4fcc713": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "33ee379e8239454f8d1223f76d4ef007": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2264b1397c0d4fdaab56889fd1608f5a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_da253cc06045482aa74ca9e218ad1d27",
              "IPY_MODEL_041f2c7de8f2456b8648b59359c6ea4a",
              "IPY_MODEL_db232a155fc24f0cae48bdcddd32e949"
            ],
            "layout": "IPY_MODEL_7b74d6eb817249789e5ec9ed6f3e34c6"
          }
        },
        "da253cc06045482aa74ca9e218ad1d27": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7d244d434c744535b7e25704f0b229f9",
            "placeholder": "​",
            "style": "IPY_MODEL_5f13fcc41ba840398ad21a40fd913485",
            "value": "Fetching 5 files: 100%"
          }
        },
        "041f2c7de8f2456b8648b59359c6ea4a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7aa25f2a684645e49314c7f9b0abc9dc",
            "max": 5,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_d92b70faad1d431eba8f031d332411fa",
            "value": 5
          }
        },
        "db232a155fc24f0cae48bdcddd32e949": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d93437249a254f01b3b75583853e3299",
            "placeholder": "​",
            "style": "IPY_MODEL_31f75dde58fe4565932a3ed809ef643f",
            "value": " 5/5 [00:00&lt;00:00, 531.93it/s]"
          }
        },
        "7b74d6eb817249789e5ec9ed6f3e34c6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7d244d434c744535b7e25704f0b229f9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5f13fcc41ba840398ad21a40fd913485": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7aa25f2a684645e49314c7f9b0abc9dc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d92b70faad1d431eba8f031d332411fa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "d93437249a254f01b3b75583853e3299": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "31f75dde58fe4565932a3ed809ef643f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install -U transformers datasets nltk rouge-score sacrebleu sentence-transformers sentencepiece fsspec==2025.3.2 bert-score --quiet\n",
        "!pip install indic-nlp-library camel-tools"
      ],
      "metadata": {
        "trusted": true,
        "id": "_HobtJ41zZYk",
        "outputId": "20bde66d-9ae2-4dac-b7a0-b9b76086196f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.status.idle": "2025-05-17T15:48:56.062775Z",
          "shell.execute_reply.started": "2025-05-17T15:45:40.577563Z",
          "shell.execute_reply": "2025-05-17T15:48:56.062039Z"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: indic-nlp-library in /usr/local/lib/python3.11/dist-packages (0.92)\n",
            "Requirement already satisfied: camel-tools in /usr/local/lib/python3.11/dist-packages (1.5.6)\n",
            "Requirement already satisfied: sphinx-argparse in /usr/local/lib/python3.11/dist-packages (from indic-nlp-library) (0.5.2)\n",
            "Requirement already satisfied: sphinx-rtd-theme in /usr/local/lib/python3.11/dist-packages (from indic-nlp-library) (3.0.2)\n",
            "Requirement already satisfied: morfessor in /usr/local/lib/python3.11/dist-packages (from indic-nlp-library) (2.0.6)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from indic-nlp-library) (2.2.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from indic-nlp-library) (1.26.4)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.11/dist-packages (from camel-tools) (1.0.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.11/dist-packages (from camel-tools) (1.17.0)\n",
            "Requirement already satisfied: docopt in /usr/local/lib/python3.11/dist-packages (from camel-tools) (0.6.2)\n",
            "Requirement already satisfied: cachetools in /usr/local/lib/python3.11/dist-packages (from camel-tools) (5.5.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from camel-tools) (1.16.0)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (from camel-tools) (1.6.1)\n",
            "Requirement already satisfied: dill in /usr/local/lib/python3.11/dist-packages (from camel-tools) (0.3.7)\n",
            "Requirement already satisfied: torch>=2.0 in /usr/local/lib/python3.11/dist-packages (from camel-tools) (2.6.0+cu124)\n",
            "Collecting transformers<4.44.0,>=4.0 (from camel-tools)\n",
            "  Using cached transformers-4.43.4-py3-none-any.whl.metadata (43 kB)\n",
            "Requirement already satisfied: editdistance in /usr/local/lib/python3.11/dist-packages (from camel-tools) (0.8.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from camel-tools) (2.32.3)\n",
            "Requirement already satisfied: emoji in /usr/local/lib/python3.11/dist-packages (from camel-tools) (2.14.1)\n",
            "Requirement already satisfied: pyrsistent in /usr/local/lib/python3.11/dist-packages (from camel-tools) (0.20.0)\n",
            "Requirement already satisfied: tabulate in /usr/local/lib/python3.11/dist-packages (from camel-tools) (0.9.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from camel-tools) (4.67.1)\n",
            "Requirement already satisfied: muddler in /usr/local/lib/python3.11/dist-packages (from camel-tools) (0.1.3)\n",
            "Requirement already satisfied: camel-kenlm>=2025.4.8 in /usr/local/lib/python3.11/dist-packages (from camel-tools) (2025.4.8)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=2.0->camel-tools) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0->camel-tools) (4.14.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=2.0->camel-tools) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0->camel-tools) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch>=2.0->camel-tools) (2025.3.2)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0->camel-tools) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0->camel-tools) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0->camel-tools) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0->camel-tools) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0->camel-tools) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0->camel-tools) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0->camel-tools) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0->camel-tools) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0->camel-tools) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0->camel-tools) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0->camel-tools) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0->camel-tools) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0->camel-tools) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0->camel-tools) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0->camel-tools) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=2.0->camel-tools) (1.3.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /usr/local/lib/python3.11/dist-packages (from transformers<4.44.0,>=4.0->camel-tools) (0.34.1)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers<4.44.0,>=4.0->camel-tools) (25.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers<4.44.0,>=4.0->camel-tools) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers<4.44.0,>=4.0->camel-tools) (2024.11.6)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.11/dist-packages (from transformers<4.44.0,>=4.0->camel-tools) (0.5.3)\n",
            "Collecting tokenizers<0.20,>=0.19 (from transformers<4.44.0,>=4.0->camel-tools)\n",
            "  Using cached tokenizers-0.19.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->indic-nlp-library) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->indic-nlp-library) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->indic-nlp-library) (2025.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->camel-tools) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->camel-tools) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->camel-tools) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->camel-tools) (2025.7.14)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->camel-tools) (1.5.1)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->camel-tools) (3.6.0)\n",
            "Requirement already satisfied: sphinx>=5.1.0 in /usr/local/lib/python3.11/dist-packages (from sphinx-argparse->indic-nlp-library) (8.2.3)\n",
            "Requirement already satisfied: docutils>=0.19 in /usr/local/lib/python3.11/dist-packages (from sphinx-argparse->indic-nlp-library) (0.21.2)\n",
            "Requirement already satisfied: sphinxcontrib-jquery<5,>=4 in /usr/local/lib/python3.11/dist-packages (from sphinx-rtd-theme->indic-nlp-library) (4.1)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers<4.44.0,>=4.0->camel-tools) (1.1.5)\n",
            "Requirement already satisfied: sphinxcontrib-applehelp>=1.0.7 in /usr/local/lib/python3.11/dist-packages (from sphinx>=5.1.0->sphinx-argparse->indic-nlp-library) (2.0.0)\n",
            "Requirement already satisfied: sphinxcontrib-devhelp>=1.0.6 in /usr/local/lib/python3.11/dist-packages (from sphinx>=5.1.0->sphinx-argparse->indic-nlp-library) (2.0.0)\n",
            "Requirement already satisfied: sphinxcontrib-htmlhelp>=2.0.6 in /usr/local/lib/python3.11/dist-packages (from sphinx>=5.1.0->sphinx-argparse->indic-nlp-library) (2.1.0)\n",
            "Requirement already satisfied: sphinxcontrib-jsmath>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from sphinx>=5.1.0->sphinx-argparse->indic-nlp-library) (1.0.1)\n",
            "Requirement already satisfied: sphinxcontrib-qthelp>=1.0.6 in /usr/local/lib/python3.11/dist-packages (from sphinx>=5.1.0->sphinx-argparse->indic-nlp-library) (2.0.0)\n",
            "Requirement already satisfied: sphinxcontrib-serializinghtml>=1.1.9 in /usr/local/lib/python3.11/dist-packages (from sphinx>=5.1.0->sphinx-argparse->indic-nlp-library) (2.0.0)\n",
            "Requirement already satisfied: Pygments>=2.17 in /usr/local/lib/python3.11/dist-packages (from sphinx>=5.1.0->sphinx-argparse->indic-nlp-library) (2.19.2)\n",
            "Requirement already satisfied: snowballstemmer>=2.2 in /usr/local/lib/python3.11/dist-packages (from sphinx>=5.1.0->sphinx-argparse->indic-nlp-library) (3.0.1)\n",
            "Requirement already satisfied: babel>=2.13 in /usr/local/lib/python3.11/dist-packages (from sphinx>=5.1.0->sphinx-argparse->indic-nlp-library) (2.17.0)\n",
            "Requirement already satisfied: alabaster>=0.7.14 in /usr/local/lib/python3.11/dist-packages (from sphinx>=5.1.0->sphinx-argparse->indic-nlp-library) (1.0.0)\n",
            "Requirement already satisfied: imagesize>=1.3 in /usr/local/lib/python3.11/dist-packages (from sphinx>=5.1.0->sphinx-argparse->indic-nlp-library) (1.4.1)\n",
            "Requirement already satisfied: roman-numerals-py>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from sphinx>=5.1.0->sphinx-argparse->indic-nlp-library) (3.1.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=2.0->camel-tools) (3.0.2)\n",
            "Using cached transformers-4.43.4-py3-none-any.whl (9.4 MB)\n",
            "Using cached tokenizers-0.19.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.6 MB)\n",
            "Installing collected packages: tokenizers, transformers\n",
            "  Attempting uninstall: tokenizers\n",
            "    Found existing installation: tokenizers 0.21.4\n",
            "    Uninstalling tokenizers-0.21.4:\n",
            "      Successfully uninstalled tokenizers-0.21.4\n",
            "  Attempting uninstall: transformers\n",
            "    Found existing installation: transformers 4.54.1\n",
            "    Uninstalling transformers-4.54.1:\n",
            "      Successfully uninstalled transformers-4.54.1\n",
            "Successfully installed tokenizers-0.19.1 transformers-4.43.4\n"
          ]
        }
      ],
      "execution_count": 1
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ[\"PYTORCH_CUDA_ALLOC_CONF\"] = \"expandable_segments:True\"\n"
      ],
      "metadata": {
        "id": "hRrrwB9yJjvG"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import Counter"
      ],
      "metadata": {
        "id": "HB61xn2s8jDh"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install unbabel-comet\n",
        "!pip install evaluate"
      ],
      "metadata": {
        "id": "Pqv2DWjy3eo5",
        "outputId": "16ea4393-5d30-49c4-cd23-a85ab53050ec",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "trusted": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: unbabel-comet in /usr/local/lib/python3.11/dist-packages (2.2.6)\n",
            "Requirement already satisfied: entmax<2.0,>=1.1 in /usr/local/lib/python3.11/dist-packages (from unbabel-comet) (1.3)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /usr/local/lib/python3.11/dist-packages (from unbabel-comet) (0.34.1)\n",
            "Requirement already satisfied: jsonargparse==3.13.1 in /usr/local/lib/python3.11/dist-packages (from unbabel-comet) (3.13.1)\n",
            "Requirement already satisfied: numpy<2.0.0,>=1.20.0 in /usr/local/lib/python3.11/dist-packages (from unbabel-comet) (1.26.4)\n",
            "Requirement already satisfied: pandas>=1.4.1 in /usr/local/lib/python3.11/dist-packages (from unbabel-comet) (2.2.2)\n",
            "Requirement already satisfied: protobuf<5.0.0,>=4.24.4 in /usr/local/lib/python3.11/dist-packages (from unbabel-comet) (4.25.8)\n",
            "Requirement already satisfied: pytorch-lightning<3.0.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from unbabel-comet) (2.5.2)\n",
            "Requirement already satisfied: sacrebleu<3.0.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from unbabel-comet) (2.5.1)\n",
            "Requirement already satisfied: scipy<2.0.0,>=1.5.4 in /usr/local/lib/python3.11/dist-packages (from unbabel-comet) (1.16.0)\n",
            "Requirement already satisfied: sentencepiece<0.3.0,>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from unbabel-comet) (0.2.0)\n",
            "Requirement already satisfied: torch>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from unbabel-comet) (2.6.0+cu124)\n",
            "Requirement already satisfied: torchmetrics<0.11.0,>=0.10.2 in /usr/local/lib/python3.11/dist-packages (from unbabel-comet) (0.10.3)\n",
            "Requirement already satisfied: transformers<5.0,>=4.17 in /usr/local/lib/python3.11/dist-packages (from unbabel-comet) (4.43.4)\n",
            "Requirement already satisfied: PyYAML>=3.13 in /usr/local/lib/python3.11/dist-packages (from jsonargparse==3.13.1->unbabel-comet) (6.0.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.19.3->unbabel-comet) (3.18.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.19.3->unbabel-comet) (2025.3.2)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.19.3->unbabel-comet) (25.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.19.3->unbabel-comet) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.19.3->unbabel-comet) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.19.3->unbabel-comet) (4.14.1)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.19.3->unbabel-comet) (1.1.5)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.4.1->unbabel-comet) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.4.1->unbabel-comet) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.4.1->unbabel-comet) (2025.2)\n",
            "Requirement already satisfied: lightning-utilities>=0.10.0 in /usr/local/lib/python3.11/dist-packages (from pytorch-lightning<3.0.0,>=2.0.0->unbabel-comet) (0.15.0)\n",
            "Requirement already satisfied: portalocker in /usr/local/lib/python3.11/dist-packages (from sacrebleu<3.0.0,>=2.0.0->unbabel-comet) (3.2.0)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.11/dist-packages (from sacrebleu<3.0.0,>=2.0.0->unbabel-comet) (2024.11.6)\n",
            "Requirement already satisfied: tabulate>=0.8.9 in /usr/local/lib/python3.11/dist-packages (from sacrebleu<3.0.0,>=2.0.0->unbabel-comet) (0.9.0)\n",
            "Requirement already satisfied: colorama in /usr/local/lib/python3.11/dist-packages (from sacrebleu<3.0.0,>=2.0.0->unbabel-comet) (0.4.6)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.11/dist-packages (from sacrebleu<3.0.0,>=2.0.0->unbabel-comet) (5.4.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.6.0->unbabel-comet) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.6.0->unbabel-comet) (3.1.6)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.6.0->unbabel-comet) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.6.0->unbabel-comet) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.6.0->unbabel-comet) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch>=1.6.0->unbabel-comet) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch>=1.6.0->unbabel-comet) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch>=1.6.0->unbabel-comet) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch>=1.6.0->unbabel-comet) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch>=1.6.0->unbabel-comet) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch>=1.6.0->unbabel-comet) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.6.0->unbabel-comet) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.6.0->unbabel-comet) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.6.0->unbabel-comet) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.6.0->unbabel-comet) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.6.0->unbabel-comet) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.6.0->unbabel-comet) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.6.0->unbabel-comet) (1.3.0)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.11/dist-packages (from transformers<5.0,>=4.17->unbabel-comet) (0.5.3)\n",
            "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.11/dist-packages (from transformers<5.0,>=4.17->unbabel-comet) (0.19.1)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]>=2022.5.0->pytorch-lightning<3.0.0,>=2.0.0->unbabel-comet) (3.12.14)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from lightning-utilities>=0.10.0->pytorch-lightning<3.0.0,>=2.0.0->unbabel-comet) (75.2.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas>=1.4.1->unbabel-comet) (1.17.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.6.0->unbabel-comet) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub<1.0,>=0.19.3->unbabel-comet) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub<1.0,>=0.19.3->unbabel-comet) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub<1.0,>=0.19.3->unbabel-comet) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub<1.0,>=0.19.3->unbabel-comet) (2025.7.14)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning<3.0.0,>=2.0.0->unbabel-comet) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning<3.0.0,>=2.0.0->unbabel-comet) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning<3.0.0,>=2.0.0->unbabel-comet) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning<3.0.0,>=2.0.0->unbabel-comet) (1.7.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning<3.0.0,>=2.0.0->unbabel-comet) (6.6.3)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning<3.0.0,>=2.0.0->unbabel-comet) (0.3.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning<3.0.0,>=2.0.0->unbabel-comet) (1.20.1)\n",
            "Requirement already satisfied: evaluate in /usr/local/lib/python3.11/dist-packages (0.4.5)\n",
            "Requirement already satisfied: datasets>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from evaluate) (2.14.4)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from evaluate) (1.26.4)\n",
            "Requirement already satisfied: dill in /usr/local/lib/python3.11/dist-packages (from evaluate) (0.3.7)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from evaluate) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.11/dist-packages (from evaluate) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.11/dist-packages (from evaluate) (4.67.1)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from evaluate) (3.5.0)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.11/dist-packages (from evaluate) (0.70.15)\n",
            "Requirement already satisfied: fsspec>=2021.05.0 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]>=2021.05.0->evaluate) (2025.3.2)\n",
            "Requirement already satisfied: huggingface-hub>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from evaluate) (0.34.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from evaluate) (25.0)\n",
            "Requirement already satisfied: pyarrow>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets>=2.0.0->evaluate) (18.1.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from datasets>=2.0.0->evaluate) (3.12.14)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from datasets>=2.0.0->evaluate) (6.0.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.7.0->evaluate) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.7.0->evaluate) (4.14.1)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.7.0->evaluate) (1.1.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->evaluate) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->evaluate) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->evaluate) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->evaluate) (2025.7.14)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->evaluate) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->evaluate) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->evaluate) (2025.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.7.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (6.6.3)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (0.3.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.20.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->evaluate) (1.17.0)\n"
          ]
        }
      ],
      "execution_count": 4
    },
    {
      "cell_type": "code",
      "source": [
        "# remove broken packages\n",
        "!pip uninstall -y transformers evaluate unbabel-comet\n",
        "\n",
        "# Reinstall known compatible versions\n",
        "!pip install --upgrade transformers evaluate unbabel-comet --no-cache-dir\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rQB3uSPEAil1",
        "outputId": "ffbf1efc-12b2-44fd-acf1-d171255b78da"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found existing installation: transformers 4.43.4\n",
            "Uninstalling transformers-4.43.4:\n",
            "  Successfully uninstalled transformers-4.43.4\n",
            "Found existing installation: evaluate 0.4.5\n",
            "Uninstalling evaluate-0.4.5:\n",
            "  Successfully uninstalled evaluate-0.4.5\n",
            "Found existing installation: unbabel-comet 2.2.6\n",
            "Uninstalling unbabel-comet-2.2.6:\n",
            "  Successfully uninstalled unbabel-comet-2.2.6\n",
            "Collecting transformers\n",
            "  Downloading transformers-4.54.1-py3-none-any.whl.metadata (41 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.7/41.7 kB\u001b[0m \u001b[31m114.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting evaluate\n",
            "  Downloading evaluate-0.4.5-py3-none-any.whl.metadata (9.5 kB)\n",
            "Collecting unbabel-comet\n",
            "  Downloading unbabel_comet-2.2.6-py3-none-any.whl.metadata (19 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.18.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.34.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.34.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (25.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.3)\n",
            "Collecting tokenizers<0.22,>=0.21 (from transformers)\n",
            "  Downloading tokenizers-0.21.4-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: datasets>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from evaluate) (2.14.4)\n",
            "Requirement already satisfied: dill in /usr/local/lib/python3.11/dist-packages (from evaluate) (0.3.7)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from evaluate) (2.2.2)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from evaluate) (3.5.0)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.11/dist-packages (from evaluate) (0.70.15)\n",
            "Requirement already satisfied: fsspec>=2021.05.0 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]>=2021.05.0->evaluate) (2025.3.2)\n",
            "Requirement already satisfied: entmax<2.0,>=1.1 in /usr/local/lib/python3.11/dist-packages (from unbabel-comet) (1.3)\n",
            "Requirement already satisfied: jsonargparse==3.13.1 in /usr/local/lib/python3.11/dist-packages (from unbabel-comet) (3.13.1)\n",
            "Requirement already satisfied: protobuf<5.0.0,>=4.24.4 in /usr/local/lib/python3.11/dist-packages (from unbabel-comet) (4.25.8)\n",
            "Requirement already satisfied: pytorch-lightning<3.0.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from unbabel-comet) (2.5.2)\n",
            "Requirement already satisfied: sacrebleu<3.0.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from unbabel-comet) (2.5.1)\n",
            "Requirement already satisfied: scipy<2.0.0,>=1.5.4 in /usr/local/lib/python3.11/dist-packages (from unbabel-comet) (1.16.0)\n",
            "Requirement already satisfied: sentencepiece<0.3.0,>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from unbabel-comet) (0.2.0)\n",
            "Requirement already satisfied: torch>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from unbabel-comet) (2.6.0+cu124)\n",
            "Requirement already satisfied: torchmetrics<0.11.0,>=0.10.2 in /usr/local/lib/python3.11/dist-packages (from unbabel-comet) (0.10.3)\n",
            "Requirement already satisfied: pyarrow>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets>=2.0.0->evaluate) (18.1.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from datasets>=2.0.0->evaluate) (3.12.14)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (4.14.1)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (1.1.5)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->evaluate) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->evaluate) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->evaluate) (2025.2)\n",
            "Requirement already satisfied: lightning-utilities>=0.10.0 in /usr/local/lib/python3.11/dist-packages (from pytorch-lightning<3.0.0,>=2.0.0->unbabel-comet) (0.15.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2025.7.14)\n",
            "Requirement already satisfied: portalocker in /usr/local/lib/python3.11/dist-packages (from sacrebleu<3.0.0,>=2.0.0->unbabel-comet) (3.2.0)\n",
            "Requirement already satisfied: tabulate>=0.8.9 in /usr/local/lib/python3.11/dist-packages (from sacrebleu<3.0.0,>=2.0.0->unbabel-comet) (0.9.0)\n",
            "Requirement already satisfied: colorama in /usr/local/lib/python3.11/dist-packages (from sacrebleu<3.0.0,>=2.0.0->unbabel-comet) (0.4.6)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.11/dist-packages (from sacrebleu<3.0.0,>=2.0.0->unbabel-comet) (5.4.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.6.0->unbabel-comet) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.6.0->unbabel-comet) (3.1.6)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.6.0->unbabel-comet) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.6.0->unbabel-comet) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.6.0->unbabel-comet) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch>=1.6.0->unbabel-comet) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch>=1.6.0->unbabel-comet) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch>=1.6.0->unbabel-comet) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch>=1.6.0->unbabel-comet) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch>=1.6.0->unbabel-comet) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch>=1.6.0->unbabel-comet) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.6.0->unbabel-comet) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.6.0->unbabel-comet) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.6.0->unbabel-comet) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.6.0->unbabel-comet) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.6.0->unbabel-comet) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.6.0->unbabel-comet) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.6.0->unbabel-comet) (1.3.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.7.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (6.6.3)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (0.3.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.20.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from lightning-utilities>=0.10.0->pytorch-lightning<3.0.0,>=2.0.0->unbabel-comet) (75.2.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->evaluate) (1.17.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.6.0->unbabel-comet) (3.0.2)\n",
            "Downloading transformers-4.54.1-py3-none-any.whl (11.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.2/11.2 MB\u001b[0m \u001b[31m244.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading evaluate-0.4.5-py3-none-any.whl (84 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.1/84.1 kB\u001b[0m \u001b[31m288.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading unbabel_comet-2.2.6-py3-none-any.whl (90 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m91.0/91.0 kB\u001b[0m \u001b[31m270.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tokenizers-0.21.4-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m257.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: tokenizers, transformers, evaluate, unbabel-comet\n",
            "  Attempting uninstall: tokenizers\n",
            "    Found existing installation: tokenizers 0.19.1\n",
            "    Uninstalling tokenizers-0.19.1:\n",
            "      Successfully uninstalled tokenizers-0.19.1\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "camel-tools 1.5.6 requires transformers<4.44.0,>=4.0, but you have transformers 4.54.1 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed evaluate-0.4.5 tokenizers-0.21.4 transformers-4.54.1 unbabel-comet-2.2.6\n"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "jfXr1epW3nY8"
      },
      "cell_type": "code",
      "source": [
        "# ─── IMPORTS ─────────────────────────────────────────────\n",
        "import os\n",
        "import json\n",
        "import hashlib\n",
        "import numpy as np\n",
        "import torch\n",
        "import pandas as pd\n",
        "import os\n",
        "from rouge_score import rouge_scorer\n",
        "from nltk.translate.meteor_score import meteor_score\n",
        "import sacrebleu\n",
        "from sentence_transformers import util\n",
        "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM, AutoModel\n",
        "from bert_score import score as bert_score\n",
        "\n",
        "from nltk.tokenize import word_tokenize\n",
        "from indicnlp.tokenize.indic_tokenize import trivial_tokenize\n",
        "from camel_tools.tokenizers.word import simple_word_tokenize\n",
        "from nltk.translate.bleu_score import corpus_bleu, SmoothingFunction\n",
        "from evaluate import load as evaluate_load"
      ],
      "outputs": [],
      "execution_count": 6
    },
    {
      "metadata": {
        "id": "1gl36JDN3nY8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2e3dfaa3-67d8-4a8d-d4d9-c20e40e26705"
      },
      "cell_type": "code",
      "source": [
        "# Install required packages\n",
        "import nltk\n",
        "nltk.download('wordnet')\n",
        "nltk.download('punkt')\n",
        "nltk.download('punkt_tab')\n"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Package punkt_tab is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "execution_count": 7
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -U gdown\n",
        "!gdown --folder 1QdxrYnelt9poi45eLT5xgObihDRb_OtV -O /content/103080"
      ],
      "metadata": {
        "id": "mtiJQX5wbiU3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "aed93421-602f-433f-934e-949003b76109"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: gdown in /usr/local/lib/python3.11/dist-packages (5.2.0)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.11/dist-packages (from gdown) (4.13.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from gdown) (3.18.0)\n",
            "Requirement already satisfied: requests[socks] in /usr/local/lib/python3.11/dist-packages (from gdown) (2.32.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from gdown) (4.67.1)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4->gdown) (2.7)\n",
            "Requirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4->gdown) (4.14.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests[socks]->gdown) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests[socks]->gdown) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests[socks]->gdown) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests[socks]->gdown) (2025.7.14)\n",
            "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.11/dist-packages (from requests[socks]->gdown) (1.7.1)\n",
            "Retrieving folder contents\n",
            "Retrieving folder 1rzaJxn-bvoSXzs4Zhyac-YWjH-HxFUEM 1_Pooling\n",
            "Processing file 1GwEAz43APaFICfzVB_VRreAEvfr1Ra20 config.json\n",
            "Processing file 1p7CoqRUhOIqXYcTuY_d-qYvZLTjcpxki config_sentence_transformers.json\n",
            "Processing file 1oUflzLJYyHewOzW_X_iDjsLxd8ppvYzx config.json\n",
            "Processing file 1IcFz-ITRtZkY6AC-x9ieb5CAdnNrzmsT modules.json\n",
            "Processing file 115xWQSGruGaZie1V8KVg4_-Xw2DjF8ah pytorch_model.bin\n",
            "Processing file 1Q7s6JhhsWmoWP09_n6zR9jJM4fU0lTz- README.md\n",
            "Processing file 1rn6Sue3wcp44qm3whgJtrVfBDkEd9BWH sentence_bert_config.json\n",
            "Processing file 1BudqNXrBJMzy7tYPxVUezizSpAQs2TMi special_tokens_map.json\n",
            "Processing file 1nWX9rbnv1V18rJN2tKrWNCI_Ulpp2-ds tokenizer_config.json\n",
            "Processing file 1Cev_MvvPrZvQ87Z0WcjH96kTVgXY9xkc tokenizer.json\n",
            "Processing file 1bkHtwyjLYLLwSHaSzvstD_dQWIKchF0B vocab.txt\n",
            "Retrieving folder contents completed\n",
            "Building directory structure\n",
            "Building directory structure completed\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1GwEAz43APaFICfzVB_VRreAEvfr1Ra20\n",
            "To: /content/103080/1_Pooling/config.json\n",
            "100% 190/190 [00:00<00:00, 1.21MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1p7CoqRUhOIqXYcTuY_d-qYvZLTjcpxki\n",
            "To: /content/103080/config_sentence_transformers.json\n",
            "100% 123/123 [00:00<00:00, 593kB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1oUflzLJYyHewOzW_X_iDjsLxd8ppvYzx\n",
            "To: /content/103080/config.json\n",
            "100% 594/594 [00:00<00:00, 3.52MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1IcFz-ITRtZkY6AC-x9ieb5CAdnNrzmsT\n",
            "To: /content/103080/modules.json\n",
            "100% 229/229 [00:00<00:00, 1.28MB/s]\n",
            "Downloading...\n",
            "From (original): https://drive.google.com/uc?id=115xWQSGruGaZie1V8KVg4_-Xw2DjF8ah\n",
            "From (redirected): https://drive.google.com/uc?id=115xWQSGruGaZie1V8KVg4_-Xw2DjF8ah&confirm=t&uuid=f0355760-0617-48b1-89b0-5a03150352fc\n",
            "To: /content/103080/pytorch_model.bin\n",
            "100% 438M/438M [00:03<00:00, 141MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1Q7s6JhhsWmoWP09_n6zR9jJM4fU0lTz-\n",
            "To: /content/103080/README.md\n",
            "100% 3.79k/3.79k [00:00<00:00, 23.6MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1rn6Sue3wcp44qm3whgJtrVfBDkEd9BWH\n",
            "To: /content/103080/sentence_bert_config.json\n",
            "100% 53.0/53.0 [00:00<00:00, 378kB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1BudqNXrBJMzy7tYPxVUezizSpAQs2TMi\n",
            "To: /content/103080/special_tokens_map.json\n",
            "100% 280/280 [00:00<00:00, 1.71MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1nWX9rbnv1V18rJN2tKrWNCI_Ulpp2-ds\n",
            "To: /content/103080/tokenizer_config.json\n",
            "100% 357/357 [00:00<00:00, 1.94MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1Cev_MvvPrZvQ87Z0WcjH96kTVgXY9xkc\n",
            "To: /content/103080/tokenizer.json\n",
            "100% 711k/711k [00:00<00:00, 78.5MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1bkHtwyjLYLLwSHaSzvstD_dQWIKchF0B\n",
            "To: /content/103080/vocab.txt\n",
            "100% 232k/232k [00:00<00:00, 97.4MB/s]\n",
            "Download completed\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Clone updated repo\n",
        "!git clone https://github.com/DrishtiShrrrma/multilingual-code-summarization-eval.git\n",
        "\n",
        "# Adjust base_dir to new path for prompt-based summaries\n",
        "base_dir = \"/content/multilingual-code-summarization-eval/prompt_analysis\"\n",
        "\n"
      ],
      "metadata": {
        "id": "msS29R9Ebx0d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f48101f1-dab9-4375-ebde-ba3e2881eb81"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'multilingual-code-summarization-eval' already exists and is not an empty directory.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from huggingface_hub import notebook_login\n",
        "notebook_login()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 330,
          "referenced_widgets": [
            "b71f17e016b243ddb7e051413279a0a3",
            "66e54ef4662e4aedbe86ef391ee044c2",
            "8d9867b997e94591971ce3cb0133bdff",
            "5bc2e9d941f24a1f968da3a93dbd8e48",
            "a98723c6c93d4f78943f9da957171b1c",
            "e1df9beca72d4136a5fd23a5cd5f4fd4",
            "9383b71bad0c4708b6af4fa98acbc436",
            "54b05ea1869b4d498241719ace739158",
            "02bf4b545bc34af58080d544ee15d7ca",
            "bd6fec188d7841b68bf9770ca2293263",
            "4193e249864f47e693812757b19cb9d9",
            "11f7dbf5c03b41598d3f2f4cbc85d684",
            "34a60250e7ca4c2a83d0627cdebe4048",
            "15202594c29b4a5481a3f0f2764226d1",
            "306a8b09209f43a399dd0939b5dc6302",
            "cebfed054acc48729a65d235b3adf1d2",
            "41055e6c3ed7496085d19aa7464e5744"
          ]
        },
        "id": "qNF0DK-YqY5d",
        "outputId": "50ab7bd4-15c4-43e3-db9f-7dad2a527b6a"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b71f17e016b243ddb7e051413279a0a3"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ─── CONFIGURATION ──────────────────────────────────────────────\n",
        "backtranslation_dir = \"backtranslations_cache\"\n",
        "os.makedirs(backtranslation_dir, exist_ok=True)\n",
        "\n",
        "\n",
        "# Mapping for summary field name → Display name\n",
        "json_field_to_lang = {\n",
        "    \"chinese\":     \"Chinese\",\n",
        "    \"french\":      \"French\",\n",
        "    \"spanish\":     \"Spanish\",\n",
        "    \"portuguese\":  \"Portuguese\",\n",
        "    \"arabic\":      \"Arabic\",\n",
        "    \"hindi\":       \"Hindi\"\n",
        "}\n",
        "\n",
        "# Mapping for Display name → M2M-100 language code (used for backtranslation)\n",
        "bt_lang_code_map = {\n",
        "    \"Chinese\":     \"zh\",\n",
        "    \"French\":      \"fr\",\n",
        "    \"Spanish\":     \"es\",\n",
        "    \"Portuguese\":  \"pt\",\n",
        "    \"Arabic\":      \"ar\",\n",
        "    \"Hindi\":       \"hi\"\n",
        "}\n",
        "\n",
        "\n",
        "# Load llamax model\n",
        "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
        "\n",
        "\n",
        "bt_model_name = \"ModelSpace/GemmaX2-28-9B-v0.1\"\n",
        "bt_model_tag = \"gemmax2-9b\"\n",
        "\n",
        "\n",
        "is_encoder_decoder = \"m2m\" in bt_model_name.lower() or \"opus\" in bt_model_name.lower()\n",
        "\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM, AutoModelForSeq2SeqLM, pipeline\n",
        "\n",
        "bt_tokenizer = AutoTokenizer.from_pretrained(bt_model_name)\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "if is_encoder_decoder:\n",
        "    bt_model = AutoModelForSeq2SeqLM.from_pretrained(bt_model_name).to(device)\n",
        "else:\n",
        "    bt_model = AutoModelForCausalLM.from_pretrained(bt_model_name, torch_dtype=torch.float16).to(device)\n",
        "bt_model.eval()\n",
        "\n",
        "\n",
        "\n",
        "# Caches\n",
        "embedding_model     = None\n",
        "bertscore_model     = None\n",
        "bertscore_tokenizer = None\n",
        "side_tokenizer      = None\n",
        "side_model          = None"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173,
          "referenced_widgets": [
            "95a0852a3d4f426b93eadeeaed57b0b2",
            "5b417f6a252f4a3e894518561f672a11",
            "18413d2d09904f4bb277b52a64448df0",
            "a94dcc96b31b48ceaed8fa9d9099b901",
            "27d1ecdd32f6414a9f4c1b173fbc0673",
            "3fd0f11b86d649dc860fe93498828872",
            "c5d58718f334432b9ffd3d018e65fbf0",
            "ab134d6402a640bfbd6fbbc5fcdeb4e6",
            "c2a330d5c5f6427eb8f7e86a7a98ca18",
            "321dd4ea701b45fb934a56fad4fcc713",
            "33ee379e8239454f8d1223f76d4ef007"
          ]
        },
        "id": "tK2Tska4XGQZ",
        "outputId": "fad2edcf-adaf-449c-f7d9-8d27690da761"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "95a0852a3d4f426b93eadeeaed57b0b2"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def sanitize_text(text: str) -> str:\n",
        "    for token in [\n",
        "        \"<|end_of_text|>\", \"</s>\", \"<s>\", \"<|eot_id|>\",\n",
        "        \"<|im_start|>user\", \"<|im_start|>assistant\", \"<|im_start|>system\", \"<|im_end|>\",\n",
        "        \"<|user|>\", \"<|assistant|>\", \"<|system|>\",\n",
        "        \"<|CHATBOT_TOKEN|>\", \"<|START_OF_TURN_TOKEN|>\", \"<|END_OF_TURN_TOKEN|>\", \"<BOS_TOKEN>\"\n",
        "    ]:\n",
        "        text = text.replace(token, \"\")\n",
        "    return text.strip()\n",
        "\n",
        "\n",
        "\n",
        "def clean_translation_output(decoded: str):\n",
        "    decoded = sanitize_text(decoded)\n",
        "\n",
        "    # Handle known prompt-style artifacts\n",
        "    for token in [\"### Response:\", \"<|CHATBOT_TOKEN|>\", \"English:\", \"Translation:\"]:\n",
        "        if token in decoded:\n",
        "            decoded = decoded.split(token, 1)[-1].strip()\n",
        "\n",
        "    # Handle chat-style output\n",
        "    if \"<|im_start|> assistant\" in decoded:\n",
        "        decoded = decoded.split(\"<|im_start|> assistant\", 1)[-1].strip()\n",
        "    elif \"<|im_start|>\" in decoded:\n",
        "        decoded = decoded.split(\"<|im_start|>\", 1)[-1].strip()\n",
        "\n",
        "    if \"<|im_end|>\" in decoded:\n",
        "        decoded = decoded.split(\"<|im_end|>\", 1)[0].strip()\n",
        "\n",
        "    return decoded.strip()\n"
      ],
      "metadata": {
        "id": "QxP0HPFvrmNf"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def prompt_template(text, src_lang, tgt_lang):\n",
        "    return f\"Translate the following text from {src_lang} to {tgt_lang}:\\n{text.strip()}\\nTranslation:\"\n",
        "\n",
        "def bt_function(text, src_lang_name):\n",
        "    key = f\"{src_lang_name}_{bt_model_tag}_{hashlib.md5(text.encode()).hexdigest()}\"\n",
        "    cache_file = os.path.join(backtranslation_dir, key + \".txt\")\n",
        "    if os.path.exists(cache_file):\n",
        "        return open(cache_file, 'r', encoding='utf-8').read()\n",
        "\n",
        "    src_lang = json_field_to_lang.get(src_lang_name.lower(), src_lang_name)\n",
        "    tgt_lang = \"English\"\n",
        "\n",
        "    is_encoder_decoder = isinstance(bt_model, AutoModelForSeq2SeqLM)\n",
        "\n",
        "    if is_encoder_decoder:\n",
        "        tgt_lang_code = \"en\"\n",
        "        src_lang_code = bt_lang_code_map.get(src_lang_name)\n",
        "        if not src_lang_code:\n",
        "            return text\n",
        "        bt_tokenizer.src_lang = src_lang_code\n",
        "        inputs = bt_tokenizer(text, return_tensors=\"pt\", padding=True, truncation=True, max_length=512)\n",
        "        inputs = {k: v.to(device) for k, v in inputs.items()}\n",
        "        output_ids = bt_model.generate(**inputs, forced_bos_token_id=bt_tokenizer.get_lang_id(tgt_lang_code))\n",
        "        output = bt_tokenizer.decode(output_ids[0], skip_special_tokens=True)\n",
        "    else:\n",
        "        prompt = prompt_template(text, src_lang, tgt_lang)\n",
        "        if hasattr(bt_tokenizer, \"apply_chat_template\"):\n",
        "            messages = [{\"role\": \"user\", \"content\": prompt}]\n",
        "            prompt = bt_tokenizer.apply_chat_template(messages, tokenize=False, add_generation_prompt=True)\n",
        "        inputs = bt_tokenizer(prompt, return_tensors=\"pt\").to(device)\n",
        "        with torch.no_grad():\n",
        "            output_ids = bt_model.generate(\n",
        "                inputs.input_ids,\n",
        "                max_new_tokens=512,\n",
        "                pad_token_id=bt_tokenizer.eos_token_id,\n",
        "                do_sample=False\n",
        "            )\n",
        "        decoded = bt_tokenizer.decode(output_ids[0], skip_special_tokens=False, clean_up_tokenization_spaces=False)\n",
        "        output = clean_translation_output(decoded)\n",
        "\n",
        "    # Clean up unwanted special token artifacts\n",
        "    output = output.replace(\"<|end_of_text|>\", \"\").strip()\n",
        "\n",
        "    with open(cache_file, 'w', encoding='utf-8') as f:\n",
        "        f.write(output)\n",
        "\n",
        "    return sanitize_text(output)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# ─── METRIC FUNCTIONS ──────────────────────────────────────────────────────\n",
        "def compute_bertscore(refs, hyps):\n",
        "    P, R, F1 = bert_score(\n",
        "        hyps,\n",
        "        refs,\n",
        "        model_type=\"xlm-roberta-large\",\n",
        "        lang=\"en\",\n",
        "        rescale_with_baseline=False\n",
        "    )\n",
        "    return {\n",
        "        \"precision\": round(P.mean().item(), 4),\n",
        "        \"recall\":    round(R.mean().item(), 4),\n",
        "        \"f1\":        round(F1.mean().item(), 4)\n",
        "    }"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-05-17T15:51:55.056893Z",
          "iopub.execute_input": "2025-05-17T15:51:55.057441Z",
          "iopub.status.idle": "2025-05-17T15:52:05.406210Z",
          "shell.execute_reply.started": "2025-05-17T15:51:55.057417Z",
          "shell.execute_reply": "2025-05-17T15:52:05.405181Z"
        },
        "id": "48Z-T6bgzZYp"
      },
      "outputs": [],
      "execution_count": 13
    },
    {
      "cell_type": "code",
      "source": [
        "# ─── MEAN POOLING (for SIDE) ───────────────────────────────────────────────\n",
        "def mean_pooling(model_output, attention_mask):\n",
        "    token_embeddings = model_output[0]\n",
        "    mask = attention_mask.unsqueeze(-1).expand(token_embeddings.size()).float()\n",
        "    return torch.sum(token_embeddings * mask, 1) / torch.clamp(mask.sum(1), min=1e-9)\n",
        "\n",
        "\n",
        "def compute_side_score(codes, hyps):\n",
        "    global side_tokenizer, side_model\n",
        "    if side_model is None:\n",
        "        checkpoint = \"/content/103080\"\n",
        "        side_tokenizer = AutoTokenizer.from_pretrained(checkpoint)\n",
        "        side_model     = AutoModel.from_pretrained(checkpoint)\n",
        "        if torch.cuda.is_available(): side_model = side_model.cuda()\n",
        "        side_model.eval()\n",
        "    scores = []\n",
        "    for code, summ in zip(codes, hyps):\n",
        "        enc = side_tokenizer([code, summ], padding=True, truncation=True, return_tensors=\"pt\")\n",
        "        if torch.cuda.is_available(): enc = {k:v.cuda() for k,v in enc.items()}\n",
        "        with torch.no_grad(): out = side_model(**enc)\n",
        "        pooled = mean_pooling(out, enc['attention_mask'])\n",
        "        normed = torch.nn.functional.normalize(pooled, p=2, dim=1)\n",
        "        scores.append(util.pytorch_cos_sim(normed[0], normed[1]).item())\n",
        "    return round(float(np.mean(scores)),4)\n",
        "\n",
        "def compute_meteor_score(refs, hyps):\n",
        "    sc = []\n",
        "    for r,h in zip(refs, hyps):\n",
        "        rt = word_tokenize(r.lower()); ht = word_tokenize(h.lower())\n",
        "        sc.append(meteor_score([rt], ht))\n",
        "    return round(float(np.mean(sc)),4)\n",
        "\n",
        "def compute_chrf_score(refs, hyps):\n",
        "  refs = [r.lower() for r in refs]\n",
        "  hyps = [h.lower() for h in hyps]\n",
        "\n",
        "  res = sacrebleu.corpus_chrf(hyps, [refs], word_order=2)\n",
        "  return round(res.score / 100, 4)\n",
        "\n",
        "## ----BLEU METRIC-----------\n",
        "def compute_bleu_sacre(refs, hyps, lang_name):\n",
        "    lang_name = lang_name.lower()\n",
        "\n",
        "    # Define tokenizer per language\n",
        "    tokenizer_map = {\n",
        "        \"chinese\": \"zh\",\n",
        "        \"french\": \"13a\",\n",
        "        \"portuguese\": \"13a\",\n",
        "        \"arabic\": \"intl\",\n",
        "        \"hindi\": \"intl\",\n",
        "        \"spanish\": \"13a\"\n",
        "    }\n",
        "\n",
        "    # Default tokenizer if language not found\n",
        "    tokenizer = tokenizer_map.get(lang_name, \"13a\")\n",
        "\n",
        "    # Compute BLEU-4\n",
        "    score = sacrebleu.corpus_bleu(hyps, [refs], tokenize=tokenizer)\n",
        "    return round(score.score / 100, 4) # Normalize to 0–1 like nltk\n",
        "\n",
        "\n",
        "\n",
        "def tokenize(text, lang):\n",
        "    lang = lang.lower()\n",
        "    if lang == \"chinese\":\n",
        "        return list(text.strip())\n",
        "    elif lang == \"arabic\":\n",
        "        return simple_word_tokenize(text)\n",
        "    elif lang == \"hindi\":\n",
        "        return trivial_tokenize(text, lang='hi')\n",
        "    elif lang in [\"french\", \"portuguese\"]:\n",
        "        return word_tokenize(text, language=lang)\n",
        "    else:\n",
        "        return text.strip().split()\n",
        "\n",
        "\n",
        "def compute_bleu_nltk(refs_tokenized, hyps_tokenized):\n",
        "    smoothie = SmoothingFunction().method1\n",
        "    score = corpus_bleu(\n",
        "        refs_tokenized,\n",
        "        hyps_tokenized,\n",
        "        weights=(0.25, 0.25, 0.25, 0.25),\n",
        "        smoothing_function=smoothie\n",
        "    )\n",
        "    return round(score, 4)\n",
        "\n",
        "## ----COMET METRIC-----------\n",
        "\n",
        "comet = evaluate_load(\"comet\", config_name=\"Unbabel/wmt22-comet-da\")\n",
        "\n",
        "def compute_comet_score(sources, references, hypotheses, batch_size=8, gpus=0):\n",
        "    result = comet.compute(\n",
        "        sources=sources,\n",
        "        predictions=hypotheses,\n",
        "        references=references,\n",
        "    )\n",
        "    per_example = result.get(\"scores\", [])\n",
        "    mean_score = float(np.mean(per_example)) if per_example else 0.0\n",
        "    return round(mean_score, 4), per_example\n",
        "\n",
        "\n",
        "# COMPUTE ALL METRICS\n",
        "def compute_all_metrics(codes, refs, hyps, lang_name, code_lang):\n",
        "    print(f\"  Computing backtranslation-based metrics for {lang_name}...\")\n",
        "    bt = [bt_function(h, lang_name) for h in hyps]\n",
        "    smoothie = SmoothingFunction().method4\n",
        "    refs_tokenized = [[tokenize(r, lang_name)] for r in refs]\n",
        "    hyps_tokenized = [tokenize(b, lang_name) for b in bt]\n",
        "\n",
        "    # Compute BLEU using tokenized inputs\n",
        "    bleu_nltk = compute_bleu_nltk(refs_tokenized, hyps_tokenized)\n",
        "\n",
        "    bleu_sacre = compute_bleu_sacre(refs, bt, lang_name)\n",
        "    bleu_diff = round(abs(bleu_nltk - bleu_sacre), 4)\n",
        "\n",
        "    scorer = rouge_scorer.RougeScorer(['rougeL'], use_stemmer=True)\n",
        "    rl = [scorer.score(r, b)['rougeL'].fmeasure for r, b in zip(refs, bt)]\n",
        "    comet_mean, comet_per_example = compute_comet_score(\n",
        "        sources=hyps,\n",
        "        references=refs,\n",
        "        hypotheses=bt\n",
        "    )\n",
        "\n",
        "    return {\n",
        "        \"bleu4_nltk\": round(bleu_nltk, 4),\n",
        "        \"bleu4_sacrebleu\": bleu_sacre,\n",
        "        \"bleu4_diff\": bleu_diff,\n",
        "        \"rougeL\": round(np.mean(rl), 4),\n",
        "        \"meteor\": compute_meteor_score(refs, bt),\n",
        "        \"chrf++\": compute_chrf_score(refs, bt),\n",
        "        \"side_bt\": compute_side_score(codes, bt),\n",
        "        \"comet_mean\": comet_mean,\n",
        "        \"comet_per_example\": comet_per_example\n",
        "    }\n",
        "\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-05-17T16:01:07.499915Z",
          "iopub.execute_input": "2025-05-17T16:01:07.500259Z"
        },
        "id": "FLA_b7_XzZYq",
        "outputId": "9817a450-df4f-475c-cd4b-919c1c4823ea",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104,
          "referenced_widgets": [
            "2264b1397c0d4fdaab56889fd1608f5a",
            "da253cc06045482aa74ca9e218ad1d27",
            "041f2c7de8f2456b8648b59359c6ea4a",
            "db232a155fc24f0cae48bdcddd32e949",
            "7b74d6eb817249789e5ec9ed6f3e34c6",
            "7d244d434c744535b7e25704f0b229f9",
            "5f13fcc41ba840398ad21a40fd913485",
            "7aa25f2a684645e49314c7f9b0abc9dc",
            "d92b70faad1d431eba8f031d332411fa",
            "d93437249a254f01b3b75583853e3299",
            "31f75dde58fe4565932a3ed809ef643f"
          ]
        }
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Fetching 5 files:   0%|          | 0/5 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "2264b1397c0d4fdaab56889fd1608f5a"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:pytorch_lightning.utilities.migration.utils:Lightning automatically upgraded your loaded checkpoint from v1.8.3.post1 to v2.5.2. To apply the upgrade to your files permanently, run `python -m pytorch_lightning.utilities.upgrade_checkpoint ../root/.cache/huggingface/hub/models--Unbabel--wmt22-comet-da/snapshots/2760a223ac957f30acfb18c8aa649b01cf1d75f2/checkpoints/model.ckpt`\n",
            "/usr/local/lib/python3.11/dist-packages/pytorch_lightning/core/saving.py:195: Found keys that are not in the model state dict but in the checkpoint: ['encoder.model.embeddings.position_ids']\n"
          ]
        }
      ],
      "execution_count": 14
    },
    {
      "cell_type": "code",
      "source": [
        "# ─── BACKTRANSLATION SANITY TEST ─────────────────────────────────────────────\n",
        "print(\"\\n🔍 Running backtranslation test...\")\n",
        "\n",
        "sample_inputs = {\n",
        "    \"Chinese\": \"我喜欢自然语言处理。\",\n",
        "    \"French\": \"J'aime le traitement automatique des langues.\",\n",
        "    \"Arabic\": \"أنا أحب معالجة اللغة الطبيعية.\",\n",
        "}\n",
        "\n",
        "for lang_name, input_text in sample_inputs.items():\n",
        "    print(f\"\\n🌐 {lang_name} Input: {input_text}\")\n",
        "    output = bt_function(input_text, lang_name)\n",
        "    print(f\"📝 Backtranslated Output: {output}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yzRAR5lCh7mY",
        "outputId": "cedfb291-417d-4036-90db-254dbb46d93c"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "🔍 Running backtranslation test...\n",
            "\n",
            "🌐 Chinese Input: 我喜欢自然语言处理。\n",
            "📝 Backtranslated Output: I love natural language processing.<eos>\n",
            "\n",
            "🌐 French Input: J'aime le traitement automatique des langues.\n",
            "📝 Backtranslated Output: I like the automatic language processing.<eos>\n",
            "\n",
            "🌐 Arabic Input: أنا أحب معالجة اللغة الطبيعية.\n",
            "📝 Backtranslated Output: I love natural language processing.<eos>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import OrderedDict\n",
        "\n",
        "def insert_backtranslations(data):\n",
        "    for entry in data:\n",
        "        new_entry = OrderedDict()\n",
        "        for key, value in entry.items():\n",
        "            new_entry[key] = value\n",
        "            if key.startswith(\"summary_\"):\n",
        "                lang_code = key.replace(\"summary_\", \"\")\n",
        "                if lang_code in json_field_to_lang:\n",
        "                    lang_name = json_field_to_lang[lang_code]\n",
        "                    gen = entry.get(key, \"\").strip()\n",
        "                    if gen:\n",
        "                        bt_key = f\"bt_{lang_code}\"\n",
        "                        new_entry[bt_key] = sanitize_text(bt_function(gen, lang_name))\n",
        "        entry.clear()\n",
        "        entry.update(new_entry)\n"
      ],
      "metadata": {
        "id": "PHfUWZpK9p3N"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "km-X3KQa3nY9",
        "outputId": "eaf09dd5-f92e-487e-a122-b6196a0ae601"
      },
      "cell_type": "code",
      "source": [
        "# ─── MAIN EVALUATION ─────────────────────────────────────\n",
        "def run_evaluation():\n",
        "    all_results = []\n",
        "    base_dir = \"/content/multilingual-code-summarization-eval/prompt_analysis\"\n",
        "    model_folders = [\"codegemma\", \"gemma-2-9b-it\", \"qwen2.5coder\", \"deepseekcoder\"]\n",
        "    prompt_subdirs = [\"prompt0\"]\n",
        "\n",
        "    bt_json_dir = \"backtranslated_jsons\"\n",
        "    os.makedirs(bt_json_dir, exist_ok=True)\n",
        "\n",
        "    for model_folder in model_folders:\n",
        "        for prompt in prompt_subdirs:\n",
        "            prompt_path = os.path.join(base_dir, model_folder, prompt)\n",
        "            if not os.path.isdir(prompt_path):\n",
        "                continue\n",
        "\n",
        "            for fname in os.listdir(prompt_path):\n",
        "                if not fname.endswith(\".json\") or not fname.startswith(\"all_languages_prompt\"):\n",
        "                    continue\n",
        "\n",
        "                summary_path = os.path.join(prompt_path, fname)\n",
        "                print(f\"\\nProcessing file: {summary_path}\")\n",
        "\n",
        "                with open(summary_path, encoding='utf-8') as f:\n",
        "                    data = json.load(f)\n",
        "\n",
        "                if not data:\n",
        "                    print(\"  Skipped: empty file\")\n",
        "                    continue\n",
        "\n",
        "                codes = [d.get(\"code\", \"\") for d in data]\n",
        "                refs = [sanitize_text(d.get(\"summary_english\", d.get(\"docstring\", \"\"))) for d in data]\n",
        "\n",
        "                model_name = data[0].get(\"model_name\", model_folder)\n",
        "                prompt_used = data[0].get(\"prompt_used\", prompt)\n",
        "\n",
        "                for field, lang_name in json_field_to_lang.items():\n",
        "                    hyp_key = f\"summary_{field}\"\n",
        "                    if hyp_key not in data[0]:\n",
        "                        print(f\"  Skipping {lang_name} — {hyp_key} not found.\")\n",
        "                        continue\n",
        "\n",
        "                    hyps = [sanitize_text(d.get(hyp_key, \"\")) for d in data]\n",
        "                    if not any(hyps):\n",
        "                        print(f\"  Skipping {lang_name} — all summaries empty.\")\n",
        "                        continue\n",
        "\n",
        "                    print(f\"  → Evaluating summaries in {lang_name}...\")\n",
        "                    bert = compute_bertscore(refs, hyps)\n",
        "                    side_original = compute_side_score(codes, hyps)\n",
        "                    # Estimate dominant programming language for this batch\n",
        "                    batch_langs = [entry.get(\"language\", \"unknown\") for entry in data]\n",
        "                    code_lang = Counter(batch_langs).most_common(1)[0][0]\n",
        "                    metrics = compute_all_metrics(codes, refs, hyps, lang_name, code_lang)\n",
        "                    side_drop = round(side_original - metrics[\"side_bt\"], 4)\n",
        "\n",
        "                    for i, entry in enumerate(data):\n",
        "                        code_lang = entry.get(\"language\", \"unknown\")\n",
        "                        print(f\"[DEBUG] Sample ID: {entry.get('id')} → programming_language = {code_lang}\")\n",
        "\n",
        "                        code = entry.get(\"code\", \"\")\n",
        "                        sample_id = entry.get(\"id\", f\"{code_lang}_{i}\")\n",
        "                        full_func = entry.get(\"whole_func_string\", code)\n",
        "                        word_len = len(full_func.strip().split())\n",
        "\n",
        "                        generated_summary = sanitize_text(entry.get(hyp_key, \"\"))\n",
        "                        backtranslated_summary = sanitize_text(bt_function(generated_summary, lang_name))\n",
        "                        reference_summary = sanitize_text(entry.get(\"summary_english\", entry.get(\"docstring\", \"\")))\n",
        "\n",
        "                        result = {\n",
        "                            \"sample_id\": sample_id,\n",
        "                            \"model_folder_name\": model_folder,\n",
        "                            \"model_name\": model_name,\n",
        "                            \"programming_language\": code_lang,\n",
        "                            \"language\": lang_name,\n",
        "                            \"prompt_used\": prompt_used,\n",
        "                            \"bt_model\": bt_model_tag,\n",
        "                            \"word_len\": word_len,\n",
        "                            \"length_bucket\": entry.get(\"length_bucket\", \"unknown\"),\n",
        "                            \"reference_summary\": reference_summary,\n",
        "                            \"generated_summary\": generated_summary,\n",
        "                            \"backtranslated_summary\": backtranslated_summary,\n",
        "                            \"bertscore_f1\": bert[\"f1\"],\n",
        "                            \"bertscore_precision\": bert[\"precision\"],\n",
        "                            \"bertscore_recall\": bert[\"recall\"],\n",
        "                            \"side_original\": side_original,\n",
        "                            \"side_bt\": metrics[\"side_bt\"],\n",
        "                            \"side_drop\": side_drop,\n",
        "                            \"bleu4_nltk\": metrics[\"bleu4_nltk\"],\n",
        "                            \"bleu4_sacrebleu\": metrics[\"bleu4_sacrebleu\"],\n",
        "                            \"bleu4_diff\": metrics[\"bleu4_diff\"],\n",
        "                            \"rougeL\": metrics[\"rougeL\"],\n",
        "                            \"meteor\": metrics[\"meteor\"],\n",
        "                            \"chrf++\": metrics[\"chrf++\"],\n",
        "                            \"comet_mean\": metrics[\"comet_mean\"],\n",
        "                            \"comet_example_score\": metrics[\"comet_per_example\"][i] if i < len(metrics[\"comet_per_example\"]) else None\n",
        "                        }\n",
        "\n",
        "                        all_results.append(result)\n",
        "\n",
        "                # Insert backtranslations into data and save\n",
        "                insert_backtranslations(data)\n",
        "                enhanced_fname = os.path.basename(summary_path).replace(\".json\", f\"_with_bt_{bt_model_tag}.json\")\n",
        "                enhanced_fpath = os.path.join(bt_json_dir, enhanced_fname)\n",
        "                with open(enhanced_fpath, \"w\", encoding='utf-8') as f:\n",
        "                    json.dump(data, f, indent=2, ensure_ascii=False)\n",
        "\n",
        "    # Save metric results\n",
        "    os.makedirs(backtranslation_dir, exist_ok=True)\n",
        "    json_out = os.path.join(backtranslation_dir, f\"new_all_scores_bt_{bt_model_tag}.json\")\n",
        "    csv_out = os.path.join(backtranslation_dir, f\"new_all_scores_bt_{bt_model_tag}.csv\")\n",
        "\n",
        "    with open(json_out, \"w\", encoding='utf-8') as f:\n",
        "        json.dump(all_results, f, indent=2, ensure_ascii=False)\n",
        "\n",
        "    pd.DataFrame(all_results).to_csv(csv_out, index=False)\n",
        "\n",
        "    print(f\"\\nSaved results to:\\n  JSON: {json_out}\\n  CSV:  {csv_out}\")\n",
        "\n",
        "\n",
        "\n",
        "run_evaluation()\n"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Processing file: /content/multilingual-code-summarization-eval/prompt_analysis/codegemma/prompt0/all_languages_prompt0_combined_codegemma-7b-it.json\n",
            "  → Evaluating summaries in Chinese...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `XLMRobertaSdpaSelfAttention.forward`.\n",
            "  return forward_call(*args, **kwargs)\n",
            "INFO:pytorch_lightning.utilities.rank_zero:💡 Tip: For seamless cloud uploads and versioning, try installing [litmodels](https://pypi.org/project/litmodels/) to enable LitModelCheckpoint, which syncs automatically with the Lightning model registry.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Computing backtranslation-based metrics for Chinese...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:pytorch_lightning.utilities.rank_zero:GPU available: True (cuda), used: True\n",
            "INFO:pytorch_lightning.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n",
            "INFO:pytorch_lightning.utilities.rank_zero:HPU available: False, using: 0 HPUs\n",
            "INFO:pytorch_lightning.utilities.rank_zero:You are using a CUDA device ('NVIDIA A100-SXM4-40GB') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
            "INFO:pytorch_lightning.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `XLMRobertaSdpaSelfAttention.forward`.\n",
            "  return forward_call(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[DEBUG] Sample ID: sample_68262 → programming_language = go\n",
            "[DEBUG] Sample ID: sample_59144 → programming_language = go\n",
            "[DEBUG] Sample ID: sample_56854 → programming_language = go\n",
            "[DEBUG] Sample ID: sample_60736 → programming_language = go\n",
            "[DEBUG] Sample ID: sample_60808 → programming_language = go\n",
            "[DEBUG] Sample ID: sample_65047 → programming_language = go\n",
            "[DEBUG] Sample ID: sample_68705 → programming_language = go\n",
            "[DEBUG] Sample ID: sample_56245 → programming_language = go\n",
            "[DEBUG] Sample ID: sample_69232 → programming_language = go\n",
            "[DEBUG] Sample ID: sample_43225 → programming_language = java\n",
            "[DEBUG] Sample ID: sample_43881 → programming_language = java\n",
            "[DEBUG] Sample ID: sample_24461 → programming_language = java\n",
            "[DEBUG] Sample ID: sample_34565 → programming_language = java\n",
            "[DEBUG] Sample ID: sample_26644 → programming_language = java\n",
            "[DEBUG] Sample ID: sample_26982 → programming_language = java\n",
            "[DEBUG] Sample ID: sample_41842 → programming_language = java\n",
            "[DEBUG] Sample ID: sample_27827 → programming_language = java\n",
            "[DEBUG] Sample ID: sample_32879 → programming_language = java\n",
            "[DEBUG] Sample ID: sample_49723 → programming_language = javascript\n",
            "[DEBUG] Sample ID: sample_52604 → programming_language = javascript\n",
            "[DEBUG] Sample ID: sample_54032 → programming_language = javascript\n",
            "[DEBUG] Sample ID: sample_52784 → programming_language = javascript\n",
            "[DEBUG] Sample ID: sample_53517 → programming_language = javascript\n",
            "[DEBUG] Sample ID: sample_53447 → programming_language = javascript\n",
            "[DEBUG] Sample ID: sample_51130 → programming_language = javascript\n",
            "[DEBUG] Sample ID: sample_49517 → programming_language = javascript\n",
            "[DEBUG] Sample ID: sample_52527 → programming_language = javascript\n",
            "[DEBUG] Sample ID: sample_93329 → programming_language = php\n",
            "[DEBUG] Sample ID: sample_83020 → programming_language = php\n",
            "[DEBUG] Sample ID: sample_91440 → programming_language = php\n",
            "[DEBUG] Sample ID: sample_73076 → programming_language = php\n",
            "[DEBUG] Sample ID: sample_94265 → programming_language = php\n",
            "[DEBUG] Sample ID: sample_83774 → programming_language = php\n",
            "[DEBUG] Sample ID: sample_82130 → programming_language = php\n",
            "[DEBUG] Sample ID: sample_88325 → programming_language = php\n",
            "[DEBUG] Sample ID: sample_74896 → programming_language = php\n",
            "[DEBUG] Sample ID: sample_8123 → programming_language = python\n",
            "[DEBUG] Sample ID: sample_15264 → programming_language = python\n",
            "[DEBUG] Sample ID: sample_21319 → programming_language = python\n",
            "[DEBUG] Sample ID: sample_13024 → programming_language = python\n",
            "[DEBUG] Sample ID: sample_21753 → programming_language = python\n",
            "[DEBUG] Sample ID: sample_10224 → programming_language = python\n",
            "[DEBUG] Sample ID: sample_1038 → programming_language = python\n",
            "[DEBUG] Sample ID: sample_14790 → programming_language = python\n",
            "[DEBUG] Sample ID: sample_20038 → programming_language = python\n",
            "[DEBUG] Sample ID: sample_71154 → programming_language = ruby\n",
            "[DEBUG] Sample ID: sample_71953 → programming_language = ruby\n",
            "[DEBUG] Sample ID: sample_71260 → programming_language = ruby\n",
            "[DEBUG] Sample ID: sample_70850 → programming_language = ruby\n",
            "[DEBUG] Sample ID: sample_70934 → programming_language = ruby\n",
            "[DEBUG] Sample ID: sample_71240 → programming_language = ruby\n",
            "[DEBUG] Sample ID: sample_70240 → programming_language = ruby\n",
            "[DEBUG] Sample ID: sample_70974 → programming_language = ruby\n",
            "[DEBUG] Sample ID: sample_70539 → programming_language = ruby\n",
            "  → Evaluating summaries in French...\n",
            "  Computing backtranslation-based metrics for French...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:pytorch_lightning.utilities.rank_zero:💡 Tip: For seamless cloud uploads and versioning, try installing [litmodels](https://pypi.org/project/litmodels/) to enable LitModelCheckpoint, which syncs automatically with the Lightning model registry.\n",
            "INFO:pytorch_lightning.utilities.rank_zero:GPU available: True (cuda), used: True\n",
            "INFO:pytorch_lightning.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n",
            "INFO:pytorch_lightning.utilities.rank_zero:HPU available: False, using: 0 HPUs\n",
            "INFO:pytorch_lightning.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `XLMRobertaSdpaSelfAttention.forward`.\n",
            "  return forward_call(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[DEBUG] Sample ID: sample_68262 → programming_language = go\n",
            "[DEBUG] Sample ID: sample_59144 → programming_language = go\n",
            "[DEBUG] Sample ID: sample_56854 → programming_language = go\n",
            "[DEBUG] Sample ID: sample_60736 → programming_language = go\n",
            "[DEBUG] Sample ID: sample_60808 → programming_language = go\n",
            "[DEBUG] Sample ID: sample_65047 → programming_language = go\n",
            "[DEBUG] Sample ID: sample_68705 → programming_language = go\n",
            "[DEBUG] Sample ID: sample_56245 → programming_language = go\n",
            "[DEBUG] Sample ID: sample_69232 → programming_language = go\n",
            "[DEBUG] Sample ID: sample_43225 → programming_language = java\n",
            "[DEBUG] Sample ID: sample_43881 → programming_language = java\n",
            "[DEBUG] Sample ID: sample_24461 → programming_language = java\n",
            "[DEBUG] Sample ID: sample_34565 → programming_language = java\n",
            "[DEBUG] Sample ID: sample_26644 → programming_language = java\n",
            "[DEBUG] Sample ID: sample_26982 → programming_language = java\n",
            "[DEBUG] Sample ID: sample_41842 → programming_language = java\n",
            "[DEBUG] Sample ID: sample_27827 → programming_language = java\n",
            "[DEBUG] Sample ID: sample_32879 → programming_language = java\n",
            "[DEBUG] Sample ID: sample_49723 → programming_language = javascript\n",
            "[DEBUG] Sample ID: sample_52604 → programming_language = javascript\n",
            "[DEBUG] Sample ID: sample_54032 → programming_language = javascript\n",
            "[DEBUG] Sample ID: sample_52784 → programming_language = javascript\n",
            "[DEBUG] Sample ID: sample_53517 → programming_language = javascript\n",
            "[DEBUG] Sample ID: sample_53447 → programming_language = javascript\n",
            "[DEBUG] Sample ID: sample_51130 → programming_language = javascript\n",
            "[DEBUG] Sample ID: sample_49517 → programming_language = javascript\n",
            "[DEBUG] Sample ID: sample_52527 → programming_language = javascript\n",
            "[DEBUG] Sample ID: sample_93329 → programming_language = php\n",
            "[DEBUG] Sample ID: sample_83020 → programming_language = php\n",
            "[DEBUG] Sample ID: sample_91440 → programming_language = php\n",
            "[DEBUG] Sample ID: sample_73076 → programming_language = php\n",
            "[DEBUG] Sample ID: sample_94265 → programming_language = php\n",
            "[DEBUG] Sample ID: sample_83774 → programming_language = php\n",
            "[DEBUG] Sample ID: sample_82130 → programming_language = php\n",
            "[DEBUG] Sample ID: sample_88325 → programming_language = php\n",
            "[DEBUG] Sample ID: sample_74896 → programming_language = php\n",
            "[DEBUG] Sample ID: sample_8123 → programming_language = python\n",
            "[DEBUG] Sample ID: sample_15264 → programming_language = python\n",
            "[DEBUG] Sample ID: sample_21319 → programming_language = python\n",
            "[DEBUG] Sample ID: sample_13024 → programming_language = python\n",
            "[DEBUG] Sample ID: sample_21753 → programming_language = python\n",
            "[DEBUG] Sample ID: sample_10224 → programming_language = python\n",
            "[DEBUG] Sample ID: sample_1038 → programming_language = python\n",
            "[DEBUG] Sample ID: sample_14790 → programming_language = python\n",
            "[DEBUG] Sample ID: sample_20038 → programming_language = python\n",
            "[DEBUG] Sample ID: sample_71154 → programming_language = ruby\n",
            "[DEBUG] Sample ID: sample_71953 → programming_language = ruby\n",
            "[DEBUG] Sample ID: sample_71260 → programming_language = ruby\n",
            "[DEBUG] Sample ID: sample_70850 → programming_language = ruby\n",
            "[DEBUG] Sample ID: sample_70934 → programming_language = ruby\n",
            "[DEBUG] Sample ID: sample_71240 → programming_language = ruby\n",
            "[DEBUG] Sample ID: sample_70240 → programming_language = ruby\n",
            "[DEBUG] Sample ID: sample_70974 → programming_language = ruby\n",
            "[DEBUG] Sample ID: sample_70539 → programming_language = ruby\n",
            "  → Evaluating summaries in Spanish...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:pytorch_lightning.utilities.rank_zero:💡 Tip: For seamless cloud uploads and versioning, try installing [litmodels](https://pypi.org/project/litmodels/) to enable LitModelCheckpoint, which syncs automatically with the Lightning model registry.\n",
            "INFO:pytorch_lightning.utilities.rank_zero:GPU available: True (cuda), used: True\n",
            "INFO:pytorch_lightning.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n",
            "INFO:pytorch_lightning.utilities.rank_zero:HPU available: False, using: 0 HPUs\n",
            "INFO:pytorch_lightning.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Computing backtranslation-based metrics for Spanish...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `XLMRobertaSdpaSelfAttention.forward`.\n",
            "  return forward_call(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[DEBUG] Sample ID: sample_68262 → programming_language = go\n",
            "[DEBUG] Sample ID: sample_59144 → programming_language = go\n",
            "[DEBUG] Sample ID: sample_56854 → programming_language = go\n",
            "[DEBUG] Sample ID: sample_60736 → programming_language = go\n",
            "[DEBUG] Sample ID: sample_60808 → programming_language = go\n",
            "[DEBUG] Sample ID: sample_65047 → programming_language = go\n",
            "[DEBUG] Sample ID: sample_68705 → programming_language = go\n",
            "[DEBUG] Sample ID: sample_56245 → programming_language = go\n",
            "[DEBUG] Sample ID: sample_69232 → programming_language = go\n",
            "[DEBUG] Sample ID: sample_43225 → programming_language = java\n",
            "[DEBUG] Sample ID: sample_43881 → programming_language = java\n",
            "[DEBUG] Sample ID: sample_24461 → programming_language = java\n",
            "[DEBUG] Sample ID: sample_34565 → programming_language = java\n",
            "[DEBUG] Sample ID: sample_26644 → programming_language = java\n",
            "[DEBUG] Sample ID: sample_26982 → programming_language = java\n",
            "[DEBUG] Sample ID: sample_41842 → programming_language = java\n",
            "[DEBUG] Sample ID: sample_27827 → programming_language = java\n",
            "[DEBUG] Sample ID: sample_32879 → programming_language = java\n",
            "[DEBUG] Sample ID: sample_49723 → programming_language = javascript\n",
            "[DEBUG] Sample ID: sample_52604 → programming_language = javascript\n",
            "[DEBUG] Sample ID: sample_54032 → programming_language = javascript\n",
            "[DEBUG] Sample ID: sample_52784 → programming_language = javascript\n",
            "[DEBUG] Sample ID: sample_53517 → programming_language = javascript\n",
            "[DEBUG] Sample ID: sample_53447 → programming_language = javascript\n",
            "[DEBUG] Sample ID: sample_51130 → programming_language = javascript\n",
            "[DEBUG] Sample ID: sample_49517 → programming_language = javascript\n",
            "[DEBUG] Sample ID: sample_52527 → programming_language = javascript\n",
            "[DEBUG] Sample ID: sample_93329 → programming_language = php\n",
            "[DEBUG] Sample ID: sample_83020 → programming_language = php\n",
            "[DEBUG] Sample ID: sample_91440 → programming_language = php\n",
            "[DEBUG] Sample ID: sample_73076 → programming_language = php\n",
            "[DEBUG] Sample ID: sample_94265 → programming_language = php\n",
            "[DEBUG] Sample ID: sample_83774 → programming_language = php\n",
            "[DEBUG] Sample ID: sample_82130 → programming_language = php\n",
            "[DEBUG] Sample ID: sample_88325 → programming_language = php\n",
            "[DEBUG] Sample ID: sample_74896 → programming_language = php\n",
            "[DEBUG] Sample ID: sample_8123 → programming_language = python\n",
            "[DEBUG] Sample ID: sample_15264 → programming_language = python\n",
            "[DEBUG] Sample ID: sample_21319 → programming_language = python\n",
            "[DEBUG] Sample ID: sample_13024 → programming_language = python\n",
            "[DEBUG] Sample ID: sample_21753 → programming_language = python\n",
            "[DEBUG] Sample ID: sample_10224 → programming_language = python\n",
            "[DEBUG] Sample ID: sample_1038 → programming_language = python\n",
            "[DEBUG] Sample ID: sample_14790 → programming_language = python\n",
            "[DEBUG] Sample ID: sample_20038 → programming_language = python\n",
            "[DEBUG] Sample ID: sample_71154 → programming_language = ruby\n",
            "[DEBUG] Sample ID: sample_71953 → programming_language = ruby\n",
            "[DEBUG] Sample ID: sample_71260 → programming_language = ruby\n",
            "[DEBUG] Sample ID: sample_70850 → programming_language = ruby\n",
            "[DEBUG] Sample ID: sample_70934 → programming_language = ruby\n",
            "[DEBUG] Sample ID: sample_71240 → programming_language = ruby\n",
            "[DEBUG] Sample ID: sample_70240 → programming_language = ruby\n",
            "[DEBUG] Sample ID: sample_70974 → programming_language = ruby\n",
            "[DEBUG] Sample ID: sample_70539 → programming_language = ruby\n",
            "  → Evaluating summaries in Portuguese...\n",
            "  Computing backtranslation-based metrics for Portuguese...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:pytorch_lightning.utilities.rank_zero:💡 Tip: For seamless cloud uploads and versioning, try installing [litmodels](https://pypi.org/project/litmodels/) to enable LitModelCheckpoint, which syncs automatically with the Lightning model registry.\n",
            "INFO:pytorch_lightning.utilities.rank_zero:GPU available: True (cuda), used: True\n",
            "INFO:pytorch_lightning.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n",
            "INFO:pytorch_lightning.utilities.rank_zero:HPU available: False, using: 0 HPUs\n",
            "INFO:pytorch_lightning.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `XLMRobertaSdpaSelfAttention.forward`.\n",
            "  return forward_call(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[DEBUG] Sample ID: sample_68262 → programming_language = go\n",
            "[DEBUG] Sample ID: sample_59144 → programming_language = go\n",
            "[DEBUG] Sample ID: sample_56854 → programming_language = go\n",
            "[DEBUG] Sample ID: sample_60736 → programming_language = go\n",
            "[DEBUG] Sample ID: sample_60808 → programming_language = go\n",
            "[DEBUG] Sample ID: sample_65047 → programming_language = go\n",
            "[DEBUG] Sample ID: sample_68705 → programming_language = go\n",
            "[DEBUG] Sample ID: sample_56245 → programming_language = go\n",
            "[DEBUG] Sample ID: sample_69232 → programming_language = go\n",
            "[DEBUG] Sample ID: sample_43225 → programming_language = java\n",
            "[DEBUG] Sample ID: sample_43881 → programming_language = java\n",
            "[DEBUG] Sample ID: sample_24461 → programming_language = java\n",
            "[DEBUG] Sample ID: sample_34565 → programming_language = java\n",
            "[DEBUG] Sample ID: sample_26644 → programming_language = java\n",
            "[DEBUG] Sample ID: sample_26982 → programming_language = java\n",
            "[DEBUG] Sample ID: sample_41842 → programming_language = java\n",
            "[DEBUG] Sample ID: sample_27827 → programming_language = java\n",
            "[DEBUG] Sample ID: sample_32879 → programming_language = java\n",
            "[DEBUG] Sample ID: sample_49723 → programming_language = javascript\n",
            "[DEBUG] Sample ID: sample_52604 → programming_language = javascript\n",
            "[DEBUG] Sample ID: sample_54032 → programming_language = javascript\n",
            "[DEBUG] Sample ID: sample_52784 → programming_language = javascript\n",
            "[DEBUG] Sample ID: sample_53517 → programming_language = javascript\n",
            "[DEBUG] Sample ID: sample_53447 → programming_language = javascript\n",
            "[DEBUG] Sample ID: sample_51130 → programming_language = javascript\n",
            "[DEBUG] Sample ID: sample_49517 → programming_language = javascript\n",
            "[DEBUG] Sample ID: sample_52527 → programming_language = javascript\n",
            "[DEBUG] Sample ID: sample_93329 → programming_language = php\n",
            "[DEBUG] Sample ID: sample_83020 → programming_language = php\n",
            "[DEBUG] Sample ID: sample_91440 → programming_language = php\n",
            "[DEBUG] Sample ID: sample_73076 → programming_language = php\n",
            "[DEBUG] Sample ID: sample_94265 → programming_language = php\n",
            "[DEBUG] Sample ID: sample_83774 → programming_language = php\n",
            "[DEBUG] Sample ID: sample_82130 → programming_language = php\n",
            "[DEBUG] Sample ID: sample_88325 → programming_language = php\n",
            "[DEBUG] Sample ID: sample_74896 → programming_language = php\n",
            "[DEBUG] Sample ID: sample_8123 → programming_language = python\n",
            "[DEBUG] Sample ID: sample_15264 → programming_language = python\n",
            "[DEBUG] Sample ID: sample_21319 → programming_language = python\n",
            "[DEBUG] Sample ID: sample_13024 → programming_language = python\n",
            "[DEBUG] Sample ID: sample_21753 → programming_language = python\n",
            "[DEBUG] Sample ID: sample_10224 → programming_language = python\n",
            "[DEBUG] Sample ID: sample_1038 → programming_language = python\n",
            "[DEBUG] Sample ID: sample_14790 → programming_language = python\n",
            "[DEBUG] Sample ID: sample_20038 → programming_language = python\n",
            "[DEBUG] Sample ID: sample_71154 → programming_language = ruby\n",
            "[DEBUG] Sample ID: sample_71953 → programming_language = ruby\n",
            "[DEBUG] Sample ID: sample_71260 → programming_language = ruby\n",
            "[DEBUG] Sample ID: sample_70850 → programming_language = ruby\n",
            "[DEBUG] Sample ID: sample_70934 → programming_language = ruby\n",
            "[DEBUG] Sample ID: sample_71240 → programming_language = ruby\n",
            "[DEBUG] Sample ID: sample_70240 → programming_language = ruby\n",
            "[DEBUG] Sample ID: sample_70974 → programming_language = ruby\n",
            "[DEBUG] Sample ID: sample_70539 → programming_language = ruby\n",
            "  → Evaluating summaries in Arabic...\n",
            "  Computing backtranslation-based metrics for Arabic...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:pytorch_lightning.utilities.rank_zero:💡 Tip: For seamless cloud uploads and versioning, try installing [litmodels](https://pypi.org/project/litmodels/) to enable LitModelCheckpoint, which syncs automatically with the Lightning model registry.\n",
            "INFO:pytorch_lightning.utilities.rank_zero:GPU available: True (cuda), used: True\n",
            "INFO:pytorch_lightning.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n",
            "INFO:pytorch_lightning.utilities.rank_zero:HPU available: False, using: 0 HPUs\n",
            "INFO:pytorch_lightning.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `XLMRobertaSdpaSelfAttention.forward`.\n",
            "  return forward_call(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[DEBUG] Sample ID: sample_68262 → programming_language = go\n",
            "[DEBUG] Sample ID: sample_59144 → programming_language = go\n",
            "[DEBUG] Sample ID: sample_56854 → programming_language = go\n",
            "[DEBUG] Sample ID: sample_60736 → programming_language = go\n",
            "[DEBUG] Sample ID: sample_60808 → programming_language = go\n",
            "[DEBUG] Sample ID: sample_65047 → programming_language = go\n",
            "[DEBUG] Sample ID: sample_68705 → programming_language = go\n",
            "[DEBUG] Sample ID: sample_56245 → programming_language = go\n",
            "[DEBUG] Sample ID: sample_69232 → programming_language = go\n",
            "[DEBUG] Sample ID: sample_43225 → programming_language = java\n",
            "[DEBUG] Sample ID: sample_43881 → programming_language = java\n",
            "[DEBUG] Sample ID: sample_24461 → programming_language = java\n",
            "[DEBUG] Sample ID: sample_34565 → programming_language = java\n",
            "[DEBUG] Sample ID: sample_26644 → programming_language = java\n",
            "[DEBUG] Sample ID: sample_26982 → programming_language = java\n",
            "[DEBUG] Sample ID: sample_41842 → programming_language = java\n",
            "[DEBUG] Sample ID: sample_27827 → programming_language = java\n",
            "[DEBUG] Sample ID: sample_32879 → programming_language = java\n",
            "[DEBUG] Sample ID: sample_49723 → programming_language = javascript\n",
            "[DEBUG] Sample ID: sample_52604 → programming_language = javascript\n",
            "[DEBUG] Sample ID: sample_54032 → programming_language = javascript\n",
            "[DEBUG] Sample ID: sample_52784 → programming_language = javascript\n",
            "[DEBUG] Sample ID: sample_53517 → programming_language = javascript\n",
            "[DEBUG] Sample ID: sample_53447 → programming_language = javascript\n",
            "[DEBUG] Sample ID: sample_51130 → programming_language = javascript\n",
            "[DEBUG] Sample ID: sample_49517 → programming_language = javascript\n",
            "[DEBUG] Sample ID: sample_52527 → programming_language = javascript\n",
            "[DEBUG] Sample ID: sample_93329 → programming_language = php\n",
            "[DEBUG] Sample ID: sample_83020 → programming_language = php\n",
            "[DEBUG] Sample ID: sample_91440 → programming_language = php\n",
            "[DEBUG] Sample ID: sample_73076 → programming_language = php\n",
            "[DEBUG] Sample ID: sample_94265 → programming_language = php\n",
            "[DEBUG] Sample ID: sample_83774 → programming_language = php\n",
            "[DEBUG] Sample ID: sample_82130 → programming_language = php\n",
            "[DEBUG] Sample ID: sample_88325 → programming_language = php\n",
            "[DEBUG] Sample ID: sample_74896 → programming_language = php\n",
            "[DEBUG] Sample ID: sample_8123 → programming_language = python\n",
            "[DEBUG] Sample ID: sample_15264 → programming_language = python\n",
            "[DEBUG] Sample ID: sample_21319 → programming_language = python\n",
            "[DEBUG] Sample ID: sample_13024 → programming_language = python\n",
            "[DEBUG] Sample ID: sample_21753 → programming_language = python\n",
            "[DEBUG] Sample ID: sample_10224 → programming_language = python\n",
            "[DEBUG] Sample ID: sample_1038 → programming_language = python\n",
            "[DEBUG] Sample ID: sample_14790 → programming_language = python\n",
            "[DEBUG] Sample ID: sample_20038 → programming_language = python\n",
            "[DEBUG] Sample ID: sample_71154 → programming_language = ruby\n",
            "[DEBUG] Sample ID: sample_71953 → programming_language = ruby\n",
            "[DEBUG] Sample ID: sample_71260 → programming_language = ruby\n",
            "[DEBUG] Sample ID: sample_70850 → programming_language = ruby\n",
            "[DEBUG] Sample ID: sample_70934 → programming_language = ruby\n",
            "[DEBUG] Sample ID: sample_71240 → programming_language = ruby\n",
            "[DEBUG] Sample ID: sample_70240 → programming_language = ruby\n",
            "[DEBUG] Sample ID: sample_70974 → programming_language = ruby\n",
            "[DEBUG] Sample ID: sample_70539 → programming_language = ruby\n",
            "  → Evaluating summaries in Hindi...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:pytorch_lightning.utilities.rank_zero:💡 Tip: For seamless cloud uploads and versioning, try installing [litmodels](https://pypi.org/project/litmodels/) to enable LitModelCheckpoint, which syncs automatically with the Lightning model registry.\n",
            "INFO:pytorch_lightning.utilities.rank_zero:GPU available: True (cuda), used: True\n",
            "INFO:pytorch_lightning.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n",
            "INFO:pytorch_lightning.utilities.rank_zero:HPU available: False, using: 0 HPUs\n",
            "INFO:pytorch_lightning.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Computing backtranslation-based metrics for Hindi...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `XLMRobertaSdpaSelfAttention.forward`.\n",
            "  return forward_call(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[DEBUG] Sample ID: sample_68262 → programming_language = go\n",
            "[DEBUG] Sample ID: sample_59144 → programming_language = go\n",
            "[DEBUG] Sample ID: sample_56854 → programming_language = go\n",
            "[DEBUG] Sample ID: sample_60736 → programming_language = go\n",
            "[DEBUG] Sample ID: sample_60808 → programming_language = go\n",
            "[DEBUG] Sample ID: sample_65047 → programming_language = go\n",
            "[DEBUG] Sample ID: sample_68705 → programming_language = go\n",
            "[DEBUG] Sample ID: sample_56245 → programming_language = go\n",
            "[DEBUG] Sample ID: sample_69232 → programming_language = go\n",
            "[DEBUG] Sample ID: sample_43225 → programming_language = java\n",
            "[DEBUG] Sample ID: sample_43881 → programming_language = java\n",
            "[DEBUG] Sample ID: sample_24461 → programming_language = java\n",
            "[DEBUG] Sample ID: sample_34565 → programming_language = java\n",
            "[DEBUG] Sample ID: sample_26644 → programming_language = java\n",
            "[DEBUG] Sample ID: sample_26982 → programming_language = java\n",
            "[DEBUG] Sample ID: sample_41842 → programming_language = java\n",
            "[DEBUG] Sample ID: sample_27827 → programming_language = java\n",
            "[DEBUG] Sample ID: sample_32879 → programming_language = java\n",
            "[DEBUG] Sample ID: sample_49723 → programming_language = javascript\n",
            "[DEBUG] Sample ID: sample_52604 → programming_language = javascript\n",
            "[DEBUG] Sample ID: sample_54032 → programming_language = javascript\n",
            "[DEBUG] Sample ID: sample_52784 → programming_language = javascript\n",
            "[DEBUG] Sample ID: sample_53517 → programming_language = javascript\n",
            "[DEBUG] Sample ID: sample_53447 → programming_language = javascript\n",
            "[DEBUG] Sample ID: sample_51130 → programming_language = javascript\n",
            "[DEBUG] Sample ID: sample_49517 → programming_language = javascript\n",
            "[DEBUG] Sample ID: sample_52527 → programming_language = javascript\n",
            "[DEBUG] Sample ID: sample_93329 → programming_language = php\n",
            "[DEBUG] Sample ID: sample_83020 → programming_language = php\n",
            "[DEBUG] Sample ID: sample_91440 → programming_language = php\n",
            "[DEBUG] Sample ID: sample_73076 → programming_language = php\n",
            "[DEBUG] Sample ID: sample_94265 → programming_language = php\n",
            "[DEBUG] Sample ID: sample_83774 → programming_language = php\n",
            "[DEBUG] Sample ID: sample_82130 → programming_language = php\n",
            "[DEBUG] Sample ID: sample_88325 → programming_language = php\n",
            "[DEBUG] Sample ID: sample_74896 → programming_language = php\n",
            "[DEBUG] Sample ID: sample_8123 → programming_language = python\n",
            "[DEBUG] Sample ID: sample_15264 → programming_language = python\n",
            "[DEBUG] Sample ID: sample_21319 → programming_language = python\n",
            "[DEBUG] Sample ID: sample_13024 → programming_language = python\n",
            "[DEBUG] Sample ID: sample_21753 → programming_language = python\n",
            "[DEBUG] Sample ID: sample_10224 → programming_language = python\n",
            "[DEBUG] Sample ID: sample_1038 → programming_language = python\n",
            "[DEBUG] Sample ID: sample_14790 → programming_language = python\n",
            "[DEBUG] Sample ID: sample_20038 → programming_language = python\n",
            "[DEBUG] Sample ID: sample_71154 → programming_language = ruby\n",
            "[DEBUG] Sample ID: sample_71953 → programming_language = ruby\n",
            "[DEBUG] Sample ID: sample_71260 → programming_language = ruby\n",
            "[DEBUG] Sample ID: sample_70850 → programming_language = ruby\n",
            "[DEBUG] Sample ID: sample_70934 → programming_language = ruby\n",
            "[DEBUG] Sample ID: sample_71240 → programming_language = ruby\n",
            "[DEBUG] Sample ID: sample_70240 → programming_language = ruby\n",
            "[DEBUG] Sample ID: sample_70974 → programming_language = ruby\n",
            "[DEBUG] Sample ID: sample_70539 → programming_language = ruby\n",
            "\n",
            "Processing file: /content/multilingual-code-summarization-eval/prompt_analysis/gemma-2-9b-it/prompt0/all_languages_prompt0_combined_gemma-2-9b-it.json\n",
            "  → Evaluating summaries in Chinese...\n",
            "  Computing backtranslation-based metrics for Chinese...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:pytorch_lightning.utilities.rank_zero:💡 Tip: For seamless cloud uploads and versioning, try installing [litmodels](https://pypi.org/project/litmodels/) to enable LitModelCheckpoint, which syncs automatically with the Lightning model registry.\n",
            "INFO:pytorch_lightning.utilities.rank_zero:GPU available: True (cuda), used: True\n",
            "INFO:pytorch_lightning.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n",
            "INFO:pytorch_lightning.utilities.rank_zero:HPU available: False, using: 0 HPUs\n",
            "INFO:pytorch_lightning.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `XLMRobertaSdpaSelfAttention.forward`.\n",
            "  return forward_call(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[DEBUG] Sample ID: sample_68262 → programming_language = go\n",
            "[DEBUG] Sample ID: sample_59144 → programming_language = go\n",
            "[DEBUG] Sample ID: sample_56854 → programming_language = go\n",
            "[DEBUG] Sample ID: sample_60736 → programming_language = go\n",
            "[DEBUG] Sample ID: sample_60808 → programming_language = go\n",
            "[DEBUG] Sample ID: sample_65047 → programming_language = go\n",
            "[DEBUG] Sample ID: sample_68705 → programming_language = go\n",
            "[DEBUG] Sample ID: sample_56245 → programming_language = go\n",
            "[DEBUG] Sample ID: sample_69232 → programming_language = go\n",
            "[DEBUG] Sample ID: sample_43225 → programming_language = java\n",
            "[DEBUG] Sample ID: sample_43881 → programming_language = java\n",
            "[DEBUG] Sample ID: sample_24461 → programming_language = java\n",
            "[DEBUG] Sample ID: sample_34565 → programming_language = java\n",
            "[DEBUG] Sample ID: sample_26644 → programming_language = java\n",
            "[DEBUG] Sample ID: sample_26982 → programming_language = java\n",
            "[DEBUG] Sample ID: sample_41842 → programming_language = java\n",
            "[DEBUG] Sample ID: sample_27827 → programming_language = java\n",
            "[DEBUG] Sample ID: sample_32879 → programming_language = java\n",
            "[DEBUG] Sample ID: sample_49723 → programming_language = javascript\n",
            "[DEBUG] Sample ID: sample_52604 → programming_language = javascript\n",
            "[DEBUG] Sample ID: sample_54032 → programming_language = javascript\n",
            "[DEBUG] Sample ID: sample_52784 → programming_language = javascript\n",
            "[DEBUG] Sample ID: sample_53517 → programming_language = javascript\n",
            "[DEBUG] Sample ID: sample_53447 → programming_language = javascript\n",
            "[DEBUG] Sample ID: sample_51130 → programming_language = javascript\n",
            "[DEBUG] Sample ID: sample_49517 → programming_language = javascript\n",
            "[DEBUG] Sample ID: sample_52527 → programming_language = javascript\n",
            "[DEBUG] Sample ID: sample_93329 → programming_language = php\n",
            "[DEBUG] Sample ID: sample_83020 → programming_language = php\n",
            "[DEBUG] Sample ID: sample_91440 → programming_language = php\n",
            "[DEBUG] Sample ID: sample_73076 → programming_language = php\n",
            "[DEBUG] Sample ID: sample_94265 → programming_language = php\n",
            "[DEBUG] Sample ID: sample_83774 → programming_language = php\n",
            "[DEBUG] Sample ID: sample_82130 → programming_language = php\n",
            "[DEBUG] Sample ID: sample_88325 → programming_language = php\n",
            "[DEBUG] Sample ID: sample_74896 → programming_language = php\n",
            "[DEBUG] Sample ID: sample_8123 → programming_language = python\n",
            "[DEBUG] Sample ID: sample_15264 → programming_language = python\n",
            "[DEBUG] Sample ID: sample_21319 → programming_language = python\n",
            "[DEBUG] Sample ID: sample_13024 → programming_language = python\n",
            "[DEBUG] Sample ID: sample_21753 → programming_language = python\n",
            "[DEBUG] Sample ID: sample_10224 → programming_language = python\n",
            "[DEBUG] Sample ID: sample_1038 → programming_language = python\n",
            "[DEBUG] Sample ID: sample_14790 → programming_language = python\n",
            "[DEBUG] Sample ID: sample_20038 → programming_language = python\n",
            "[DEBUG] Sample ID: sample_71154 → programming_language = ruby\n",
            "[DEBUG] Sample ID: sample_71953 → programming_language = ruby\n",
            "[DEBUG] Sample ID: sample_71260 → programming_language = ruby\n",
            "[DEBUG] Sample ID: sample_70850 → programming_language = ruby\n",
            "[DEBUG] Sample ID: sample_70934 → programming_language = ruby\n",
            "[DEBUG] Sample ID: sample_71240 → programming_language = ruby\n",
            "[DEBUG] Sample ID: sample_70240 → programming_language = ruby\n",
            "[DEBUG] Sample ID: sample_70974 → programming_language = ruby\n",
            "[DEBUG] Sample ID: sample_70539 → programming_language = ruby\n",
            "  → Evaluating summaries in French...\n",
            "  Computing backtranslation-based metrics for French...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:pytorch_lightning.utilities.rank_zero:💡 Tip: For seamless cloud uploads and versioning, try installing [litmodels](https://pypi.org/project/litmodels/) to enable LitModelCheckpoint, which syncs automatically with the Lightning model registry.\n",
            "INFO:pytorch_lightning.utilities.rank_zero:GPU available: True (cuda), used: True\n",
            "INFO:pytorch_lightning.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n",
            "INFO:pytorch_lightning.utilities.rank_zero:HPU available: False, using: 0 HPUs\n",
            "INFO:pytorch_lightning.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `XLMRobertaSdpaSelfAttention.forward`.\n",
            "  return forward_call(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[DEBUG] Sample ID: sample_68262 → programming_language = go\n",
            "[DEBUG] Sample ID: sample_59144 → programming_language = go\n",
            "[DEBUG] Sample ID: sample_56854 → programming_language = go\n",
            "[DEBUG] Sample ID: sample_60736 → programming_language = go\n",
            "[DEBUG] Sample ID: sample_60808 → programming_language = go\n",
            "[DEBUG] Sample ID: sample_65047 → programming_language = go\n",
            "[DEBUG] Sample ID: sample_68705 → programming_language = go\n",
            "[DEBUG] Sample ID: sample_56245 → programming_language = go\n",
            "[DEBUG] Sample ID: sample_69232 → programming_language = go\n",
            "[DEBUG] Sample ID: sample_43225 → programming_language = java\n",
            "[DEBUG] Sample ID: sample_43881 → programming_language = java\n",
            "[DEBUG] Sample ID: sample_24461 → programming_language = java\n",
            "[DEBUG] Sample ID: sample_34565 → programming_language = java\n",
            "[DEBUG] Sample ID: sample_26644 → programming_language = java\n",
            "[DEBUG] Sample ID: sample_26982 → programming_language = java\n",
            "[DEBUG] Sample ID: sample_41842 → programming_language = java\n",
            "[DEBUG] Sample ID: sample_27827 → programming_language = java\n",
            "[DEBUG] Sample ID: sample_32879 → programming_language = java\n",
            "[DEBUG] Sample ID: sample_49723 → programming_language = javascript\n",
            "[DEBUG] Sample ID: sample_52604 → programming_language = javascript\n",
            "[DEBUG] Sample ID: sample_54032 → programming_language = javascript\n",
            "[DEBUG] Sample ID: sample_52784 → programming_language = javascript\n",
            "[DEBUG] Sample ID: sample_53517 → programming_language = javascript\n",
            "[DEBUG] Sample ID: sample_53447 → programming_language = javascript\n",
            "[DEBUG] Sample ID: sample_51130 → programming_language = javascript\n",
            "[DEBUG] Sample ID: sample_49517 → programming_language = javascript\n",
            "[DEBUG] Sample ID: sample_52527 → programming_language = javascript\n",
            "[DEBUG] Sample ID: sample_93329 → programming_language = php\n",
            "[DEBUG] Sample ID: sample_83020 → programming_language = php\n",
            "[DEBUG] Sample ID: sample_91440 → programming_language = php\n",
            "[DEBUG] Sample ID: sample_73076 → programming_language = php\n",
            "[DEBUG] Sample ID: sample_94265 → programming_language = php\n",
            "[DEBUG] Sample ID: sample_83774 → programming_language = php\n",
            "[DEBUG] Sample ID: sample_82130 → programming_language = php\n",
            "[DEBUG] Sample ID: sample_88325 → programming_language = php\n",
            "[DEBUG] Sample ID: sample_74896 → programming_language = php\n",
            "[DEBUG] Sample ID: sample_8123 → programming_language = python\n",
            "[DEBUG] Sample ID: sample_15264 → programming_language = python\n",
            "[DEBUG] Sample ID: sample_21319 → programming_language = python\n",
            "[DEBUG] Sample ID: sample_13024 → programming_language = python\n",
            "[DEBUG] Sample ID: sample_21753 → programming_language = python\n",
            "[DEBUG] Sample ID: sample_10224 → programming_language = python\n",
            "[DEBUG] Sample ID: sample_1038 → programming_language = python\n",
            "[DEBUG] Sample ID: sample_14790 → programming_language = python\n",
            "[DEBUG] Sample ID: sample_20038 → programming_language = python\n",
            "[DEBUG] Sample ID: sample_71154 → programming_language = ruby\n",
            "[DEBUG] Sample ID: sample_71953 → programming_language = ruby\n",
            "[DEBUG] Sample ID: sample_71260 → programming_language = ruby\n",
            "[DEBUG] Sample ID: sample_70850 → programming_language = ruby\n",
            "[DEBUG] Sample ID: sample_70934 → programming_language = ruby\n",
            "[DEBUG] Sample ID: sample_71240 → programming_language = ruby\n",
            "[DEBUG] Sample ID: sample_70240 → programming_language = ruby\n",
            "[DEBUG] Sample ID: sample_70974 → programming_language = ruby\n",
            "[DEBUG] Sample ID: sample_70539 → programming_language = ruby\n",
            "  → Evaluating summaries in Spanish...\n",
            "  Computing backtranslation-based metrics for Spanish...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:pytorch_lightning.utilities.rank_zero:💡 Tip: For seamless cloud uploads and versioning, try installing [litmodels](https://pypi.org/project/litmodels/) to enable LitModelCheckpoint, which syncs automatically with the Lightning model registry.\n",
            "INFO:pytorch_lightning.utilities.rank_zero:GPU available: True (cuda), used: True\n",
            "INFO:pytorch_lightning.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n",
            "INFO:pytorch_lightning.utilities.rank_zero:HPU available: False, using: 0 HPUs\n",
            "INFO:pytorch_lightning.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `XLMRobertaSdpaSelfAttention.forward`.\n",
            "  return forward_call(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[DEBUG] Sample ID: sample_68262 → programming_language = go\n",
            "[DEBUG] Sample ID: sample_59144 → programming_language = go\n",
            "[DEBUG] Sample ID: sample_56854 → programming_language = go\n",
            "[DEBUG] Sample ID: sample_60736 → programming_language = go\n",
            "[DEBUG] Sample ID: sample_60808 → programming_language = go\n",
            "[DEBUG] Sample ID: sample_65047 → programming_language = go\n",
            "[DEBUG] Sample ID: sample_68705 → programming_language = go\n",
            "[DEBUG] Sample ID: sample_56245 → programming_language = go\n",
            "[DEBUG] Sample ID: sample_69232 → programming_language = go\n",
            "[DEBUG] Sample ID: sample_43225 → programming_language = java\n",
            "[DEBUG] Sample ID: sample_43881 → programming_language = java\n",
            "[DEBUG] Sample ID: sample_24461 → programming_language = java\n",
            "[DEBUG] Sample ID: sample_34565 → programming_language = java\n",
            "[DEBUG] Sample ID: sample_26644 → programming_language = java\n",
            "[DEBUG] Sample ID: sample_26982 → programming_language = java\n",
            "[DEBUG] Sample ID: sample_41842 → programming_language = java\n",
            "[DEBUG] Sample ID: sample_27827 → programming_language = java\n",
            "[DEBUG] Sample ID: sample_32879 → programming_language = java\n",
            "[DEBUG] Sample ID: sample_49723 → programming_language = javascript\n",
            "[DEBUG] Sample ID: sample_52604 → programming_language = javascript\n",
            "[DEBUG] Sample ID: sample_54032 → programming_language = javascript\n",
            "[DEBUG] Sample ID: sample_52784 → programming_language = javascript\n",
            "[DEBUG] Sample ID: sample_53517 → programming_language = javascript\n",
            "[DEBUG] Sample ID: sample_53447 → programming_language = javascript\n",
            "[DEBUG] Sample ID: sample_51130 → programming_language = javascript\n",
            "[DEBUG] Sample ID: sample_49517 → programming_language = javascript\n",
            "[DEBUG] Sample ID: sample_52527 → programming_language = javascript\n",
            "[DEBUG] Sample ID: sample_93329 → programming_language = php\n",
            "[DEBUG] Sample ID: sample_83020 → programming_language = php\n",
            "[DEBUG] Sample ID: sample_91440 → programming_language = php\n",
            "[DEBUG] Sample ID: sample_73076 → programming_language = php\n",
            "[DEBUG] Sample ID: sample_94265 → programming_language = php\n",
            "[DEBUG] Sample ID: sample_83774 → programming_language = php\n",
            "[DEBUG] Sample ID: sample_82130 → programming_language = php\n",
            "[DEBUG] Sample ID: sample_88325 → programming_language = php\n",
            "[DEBUG] Sample ID: sample_74896 → programming_language = php\n",
            "[DEBUG] Sample ID: sample_8123 → programming_language = python\n",
            "[DEBUG] Sample ID: sample_15264 → programming_language = python\n",
            "[DEBUG] Sample ID: sample_21319 → programming_language = python\n",
            "[DEBUG] Sample ID: sample_13024 → programming_language = python\n",
            "[DEBUG] Sample ID: sample_21753 → programming_language = python\n",
            "[DEBUG] Sample ID: sample_10224 → programming_language = python\n",
            "[DEBUG] Sample ID: sample_1038 → programming_language = python\n",
            "[DEBUG] Sample ID: sample_14790 → programming_language = python\n",
            "[DEBUG] Sample ID: sample_20038 → programming_language = python\n",
            "[DEBUG] Sample ID: sample_71154 → programming_language = ruby\n",
            "[DEBUG] Sample ID: sample_71953 → programming_language = ruby\n",
            "[DEBUG] Sample ID: sample_71260 → programming_language = ruby\n",
            "[DEBUG] Sample ID: sample_70850 → programming_language = ruby\n",
            "[DEBUG] Sample ID: sample_70934 → programming_language = ruby\n",
            "[DEBUG] Sample ID: sample_71240 → programming_language = ruby\n",
            "[DEBUG] Sample ID: sample_70240 → programming_language = ruby\n",
            "[DEBUG] Sample ID: sample_70974 → programming_language = ruby\n",
            "[DEBUG] Sample ID: sample_70539 → programming_language = ruby\n",
            "  → Evaluating summaries in Portuguese...\n",
            "  Computing backtranslation-based metrics for Portuguese...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:pytorch_lightning.utilities.rank_zero:💡 Tip: For seamless cloud uploads and versioning, try installing [litmodels](https://pypi.org/project/litmodels/) to enable LitModelCheckpoint, which syncs automatically with the Lightning model registry.\n",
            "INFO:pytorch_lightning.utilities.rank_zero:GPU available: True (cuda), used: True\n",
            "INFO:pytorch_lightning.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n",
            "INFO:pytorch_lightning.utilities.rank_zero:HPU available: False, using: 0 HPUs\n",
            "INFO:pytorch_lightning.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `XLMRobertaSdpaSelfAttention.forward`.\n",
            "  return forward_call(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[DEBUG] Sample ID: sample_68262 → programming_language = go\n",
            "[DEBUG] Sample ID: sample_59144 → programming_language = go\n",
            "[DEBUG] Sample ID: sample_56854 → programming_language = go\n",
            "[DEBUG] Sample ID: sample_60736 → programming_language = go\n",
            "[DEBUG] Sample ID: sample_60808 → programming_language = go\n",
            "[DEBUG] Sample ID: sample_65047 → programming_language = go\n",
            "[DEBUG] Sample ID: sample_68705 → programming_language = go\n",
            "[DEBUG] Sample ID: sample_56245 → programming_language = go\n",
            "[DEBUG] Sample ID: sample_69232 → programming_language = go\n",
            "[DEBUG] Sample ID: sample_43225 → programming_language = java\n",
            "[DEBUG] Sample ID: sample_43881 → programming_language = java\n",
            "[DEBUG] Sample ID: sample_24461 → programming_language = java\n",
            "[DEBUG] Sample ID: sample_34565 → programming_language = java\n",
            "[DEBUG] Sample ID: sample_26644 → programming_language = java\n",
            "[DEBUG] Sample ID: sample_26982 → programming_language = java\n",
            "[DEBUG] Sample ID: sample_41842 → programming_language = java\n",
            "[DEBUG] Sample ID: sample_27827 → programming_language = java\n",
            "[DEBUG] Sample ID: sample_32879 → programming_language = java\n",
            "[DEBUG] Sample ID: sample_49723 → programming_language = javascript\n",
            "[DEBUG] Sample ID: sample_52604 → programming_language = javascript\n",
            "[DEBUG] Sample ID: sample_54032 → programming_language = javascript\n",
            "[DEBUG] Sample ID: sample_52784 → programming_language = javascript\n",
            "[DEBUG] Sample ID: sample_53517 → programming_language = javascript\n",
            "[DEBUG] Sample ID: sample_53447 → programming_language = javascript\n",
            "[DEBUG] Sample ID: sample_51130 → programming_language = javascript\n",
            "[DEBUG] Sample ID: sample_49517 → programming_language = javascript\n",
            "[DEBUG] Sample ID: sample_52527 → programming_language = javascript\n",
            "[DEBUG] Sample ID: sample_93329 → programming_language = php\n",
            "[DEBUG] Sample ID: sample_83020 → programming_language = php\n",
            "[DEBUG] Sample ID: sample_91440 → programming_language = php\n",
            "[DEBUG] Sample ID: sample_73076 → programming_language = php\n",
            "[DEBUG] Sample ID: sample_94265 → programming_language = php\n",
            "[DEBUG] Sample ID: sample_83774 → programming_language = php\n",
            "[DEBUG] Sample ID: sample_82130 → programming_language = php\n",
            "[DEBUG] Sample ID: sample_88325 → programming_language = php\n",
            "[DEBUG] Sample ID: sample_74896 → programming_language = php\n",
            "[DEBUG] Sample ID: sample_8123 → programming_language = python\n",
            "[DEBUG] Sample ID: sample_15264 → programming_language = python\n",
            "[DEBUG] Sample ID: sample_21319 → programming_language = python\n",
            "[DEBUG] Sample ID: sample_13024 → programming_language = python\n",
            "[DEBUG] Sample ID: sample_21753 → programming_language = python\n",
            "[DEBUG] Sample ID: sample_10224 → programming_language = python\n",
            "[DEBUG] Sample ID: sample_1038 → programming_language = python\n",
            "[DEBUG] Sample ID: sample_14790 → programming_language = python\n",
            "[DEBUG] Sample ID: sample_20038 → programming_language = python\n",
            "[DEBUG] Sample ID: sample_71154 → programming_language = ruby\n",
            "[DEBUG] Sample ID: sample_71953 → programming_language = ruby\n",
            "[DEBUG] Sample ID: sample_71260 → programming_language = ruby\n",
            "[DEBUG] Sample ID: sample_70850 → programming_language = ruby\n",
            "[DEBUG] Sample ID: sample_70934 → programming_language = ruby\n",
            "[DEBUG] Sample ID: sample_71240 → programming_language = ruby\n",
            "[DEBUG] Sample ID: sample_70240 → programming_language = ruby\n",
            "[DEBUG] Sample ID: sample_70974 → programming_language = ruby\n",
            "[DEBUG] Sample ID: sample_70539 → programming_language = ruby\n",
            "  → Evaluating summaries in Arabic...\n",
            "  Computing backtranslation-based metrics for Arabic...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:pytorch_lightning.utilities.rank_zero:💡 Tip: For seamless cloud uploads and versioning, try installing [litmodels](https://pypi.org/project/litmodels/) to enable LitModelCheckpoint, which syncs automatically with the Lightning model registry.\n",
            "INFO:pytorch_lightning.utilities.rank_zero:GPU available: True (cuda), used: True\n",
            "INFO:pytorch_lightning.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n",
            "INFO:pytorch_lightning.utilities.rank_zero:HPU available: False, using: 0 HPUs\n",
            "INFO:pytorch_lightning.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `XLMRobertaSdpaSelfAttention.forward`.\n",
            "  return forward_call(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[DEBUG] Sample ID: sample_68262 → programming_language = go\n",
            "[DEBUG] Sample ID: sample_59144 → programming_language = go\n",
            "[DEBUG] Sample ID: sample_56854 → programming_language = go\n",
            "[DEBUG] Sample ID: sample_60736 → programming_language = go\n",
            "[DEBUG] Sample ID: sample_60808 → programming_language = go\n",
            "[DEBUG] Sample ID: sample_65047 → programming_language = go\n",
            "[DEBUG] Sample ID: sample_68705 → programming_language = go\n",
            "[DEBUG] Sample ID: sample_56245 → programming_language = go\n",
            "[DEBUG] Sample ID: sample_69232 → programming_language = go\n",
            "[DEBUG] Sample ID: sample_43225 → programming_language = java\n",
            "[DEBUG] Sample ID: sample_43881 → programming_language = java\n",
            "[DEBUG] Sample ID: sample_24461 → programming_language = java\n",
            "[DEBUG] Sample ID: sample_34565 → programming_language = java\n",
            "[DEBUG] Sample ID: sample_26644 → programming_language = java\n",
            "[DEBUG] Sample ID: sample_26982 → programming_language = java\n",
            "[DEBUG] Sample ID: sample_41842 → programming_language = java\n",
            "[DEBUG] Sample ID: sample_27827 → programming_language = java\n",
            "[DEBUG] Sample ID: sample_32879 → programming_language = java\n",
            "[DEBUG] Sample ID: sample_49723 → programming_language = javascript\n",
            "[DEBUG] Sample ID: sample_52604 → programming_language = javascript\n",
            "[DEBUG] Sample ID: sample_54032 → programming_language = javascript\n",
            "[DEBUG] Sample ID: sample_52784 → programming_language = javascript\n",
            "[DEBUG] Sample ID: sample_53517 → programming_language = javascript\n",
            "[DEBUG] Sample ID: sample_53447 → programming_language = javascript\n",
            "[DEBUG] Sample ID: sample_51130 → programming_language = javascript\n",
            "[DEBUG] Sample ID: sample_49517 → programming_language = javascript\n",
            "[DEBUG] Sample ID: sample_52527 → programming_language = javascript\n",
            "[DEBUG] Sample ID: sample_93329 → programming_language = php\n",
            "[DEBUG] Sample ID: sample_83020 → programming_language = php\n",
            "[DEBUG] Sample ID: sample_91440 → programming_language = php\n",
            "[DEBUG] Sample ID: sample_73076 → programming_language = php\n",
            "[DEBUG] Sample ID: sample_94265 → programming_language = php\n",
            "[DEBUG] Sample ID: sample_83774 → programming_language = php\n",
            "[DEBUG] Sample ID: sample_82130 → programming_language = php\n",
            "[DEBUG] Sample ID: sample_88325 → programming_language = php\n",
            "[DEBUG] Sample ID: sample_74896 → programming_language = php\n",
            "[DEBUG] Sample ID: sample_8123 → programming_language = python\n",
            "[DEBUG] Sample ID: sample_15264 → programming_language = python\n",
            "[DEBUG] Sample ID: sample_21319 → programming_language = python\n",
            "[DEBUG] Sample ID: sample_13024 → programming_language = python\n",
            "[DEBUG] Sample ID: sample_21753 → programming_language = python\n",
            "[DEBUG] Sample ID: sample_10224 → programming_language = python\n",
            "[DEBUG] Sample ID: sample_1038 → programming_language = python\n",
            "[DEBUG] Sample ID: sample_14790 → programming_language = python\n",
            "[DEBUG] Sample ID: sample_20038 → programming_language = python\n",
            "[DEBUG] Sample ID: sample_71154 → programming_language = ruby\n",
            "[DEBUG] Sample ID: sample_71953 → programming_language = ruby\n",
            "[DEBUG] Sample ID: sample_71260 → programming_language = ruby\n",
            "[DEBUG] Sample ID: sample_70850 → programming_language = ruby\n",
            "[DEBUG] Sample ID: sample_70934 → programming_language = ruby\n",
            "[DEBUG] Sample ID: sample_71240 → programming_language = ruby\n",
            "[DEBUG] Sample ID: sample_70240 → programming_language = ruby\n",
            "[DEBUG] Sample ID: sample_70974 → programming_language = ruby\n",
            "[DEBUG] Sample ID: sample_70539 → programming_language = ruby\n",
            "  → Evaluating summaries in Hindi...\n",
            "  Computing backtranslation-based metrics for Hindi...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:pytorch_lightning.utilities.rank_zero:💡 Tip: For seamless cloud uploads and versioning, try installing [litmodels](https://pypi.org/project/litmodels/) to enable LitModelCheckpoint, which syncs automatically with the Lightning model registry.\n",
            "INFO:pytorch_lightning.utilities.rank_zero:GPU available: True (cuda), used: True\n",
            "INFO:pytorch_lightning.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n",
            "INFO:pytorch_lightning.utilities.rank_zero:HPU available: False, using: 0 HPUs\n",
            "INFO:pytorch_lightning.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `XLMRobertaSdpaSelfAttention.forward`.\n",
            "  return forward_call(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[DEBUG] Sample ID: sample_68262 → programming_language = go\n",
            "[DEBUG] Sample ID: sample_59144 → programming_language = go\n",
            "[DEBUG] Sample ID: sample_56854 → programming_language = go\n",
            "[DEBUG] Sample ID: sample_60736 → programming_language = go\n",
            "[DEBUG] Sample ID: sample_60808 → programming_language = go\n",
            "[DEBUG] Sample ID: sample_65047 → programming_language = go\n",
            "[DEBUG] Sample ID: sample_68705 → programming_language = go\n",
            "[DEBUG] Sample ID: sample_56245 → programming_language = go\n",
            "[DEBUG] Sample ID: sample_69232 → programming_language = go\n",
            "[DEBUG] Sample ID: sample_43225 → programming_language = java\n",
            "[DEBUG] Sample ID: sample_43881 → programming_language = java\n",
            "[DEBUG] Sample ID: sample_24461 → programming_language = java\n",
            "[DEBUG] Sample ID: sample_34565 → programming_language = java\n",
            "[DEBUG] Sample ID: sample_26644 → programming_language = java\n",
            "[DEBUG] Sample ID: sample_26982 → programming_language = java\n",
            "[DEBUG] Sample ID: sample_41842 → programming_language = java\n",
            "[DEBUG] Sample ID: sample_27827 → programming_language = java\n",
            "[DEBUG] Sample ID: sample_32879 → programming_language = java\n",
            "[DEBUG] Sample ID: sample_49723 → programming_language = javascript\n",
            "[DEBUG] Sample ID: sample_52604 → programming_language = javascript\n",
            "[DEBUG] Sample ID: sample_54032 → programming_language = javascript\n",
            "[DEBUG] Sample ID: sample_52784 → programming_language = javascript\n",
            "[DEBUG] Sample ID: sample_53517 → programming_language = javascript\n",
            "[DEBUG] Sample ID: sample_53447 → programming_language = javascript\n",
            "[DEBUG] Sample ID: sample_51130 → programming_language = javascript\n",
            "[DEBUG] Sample ID: sample_49517 → programming_language = javascript\n",
            "[DEBUG] Sample ID: sample_52527 → programming_language = javascript\n",
            "[DEBUG] Sample ID: sample_93329 → programming_language = php\n",
            "[DEBUG] Sample ID: sample_83020 → programming_language = php\n",
            "[DEBUG] Sample ID: sample_91440 → programming_language = php\n",
            "[DEBUG] Sample ID: sample_73076 → programming_language = php\n",
            "[DEBUG] Sample ID: sample_94265 → programming_language = php\n",
            "[DEBUG] Sample ID: sample_83774 → programming_language = php\n",
            "[DEBUG] Sample ID: sample_82130 → programming_language = php\n",
            "[DEBUG] Sample ID: sample_88325 → programming_language = php\n",
            "[DEBUG] Sample ID: sample_74896 → programming_language = php\n",
            "[DEBUG] Sample ID: sample_8123 → programming_language = python\n",
            "[DEBUG] Sample ID: sample_15264 → programming_language = python\n",
            "[DEBUG] Sample ID: sample_21319 → programming_language = python\n",
            "[DEBUG] Sample ID: sample_13024 → programming_language = python\n",
            "[DEBUG] Sample ID: sample_21753 → programming_language = python\n",
            "[DEBUG] Sample ID: sample_10224 → programming_language = python\n",
            "[DEBUG] Sample ID: sample_1038 → programming_language = python\n",
            "[DEBUG] Sample ID: sample_14790 → programming_language = python\n",
            "[DEBUG] Sample ID: sample_20038 → programming_language = python\n",
            "[DEBUG] Sample ID: sample_71154 → programming_language = ruby\n",
            "[DEBUG] Sample ID: sample_71953 → programming_language = ruby\n",
            "[DEBUG] Sample ID: sample_71260 → programming_language = ruby\n",
            "[DEBUG] Sample ID: sample_70850 → programming_language = ruby\n",
            "[DEBUG] Sample ID: sample_70934 → programming_language = ruby\n",
            "[DEBUG] Sample ID: sample_71240 → programming_language = ruby\n",
            "[DEBUG] Sample ID: sample_70240 → programming_language = ruby\n",
            "[DEBUG] Sample ID: sample_70974 → programming_language = ruby\n",
            "[DEBUG] Sample ID: sample_70539 → programming_language = ruby\n",
            "\n",
            "Processing file: /content/multilingual-code-summarization-eval/prompt_analysis/qwen2.5coder/prompt0/all_languages_prompt0_combined_Qwen2.5-Coder-7B-Instruct.json\n",
            "  → Evaluating summaries in Chinese...\n",
            "  Computing backtranslation-based metrics for Chinese...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:pytorch_lightning.utilities.rank_zero:💡 Tip: For seamless cloud uploads and versioning, try installing [litmodels](https://pypi.org/project/litmodels/) to enable LitModelCheckpoint, which syncs automatically with the Lightning model registry.\n",
            "INFO:pytorch_lightning.utilities.rank_zero:GPU available: True (cuda), used: True\n",
            "INFO:pytorch_lightning.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n",
            "INFO:pytorch_lightning.utilities.rank_zero:HPU available: False, using: 0 HPUs\n",
            "INFO:pytorch_lightning.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `XLMRobertaSdpaSelfAttention.forward`.\n",
            "  return forward_call(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[DEBUG] Sample ID: sample_68262 → programming_language = go\n",
            "[DEBUG] Sample ID: sample_59144 → programming_language = go\n",
            "[DEBUG] Sample ID: sample_56854 → programming_language = go\n",
            "[DEBUG] Sample ID: sample_60736 → programming_language = go\n",
            "[DEBUG] Sample ID: sample_60808 → programming_language = go\n",
            "[DEBUG] Sample ID: sample_65047 → programming_language = go\n",
            "[DEBUG] Sample ID: sample_68705 → programming_language = go\n",
            "[DEBUG] Sample ID: sample_56245 → programming_language = go\n",
            "[DEBUG] Sample ID: sample_69232 → programming_language = go\n",
            "[DEBUG] Sample ID: sample_43225 → programming_language = java\n",
            "[DEBUG] Sample ID: sample_43881 → programming_language = java\n",
            "[DEBUG] Sample ID: sample_24461 → programming_language = java\n",
            "[DEBUG] Sample ID: sample_34565 → programming_language = java\n",
            "[DEBUG] Sample ID: sample_26644 → programming_language = java\n",
            "[DEBUG] Sample ID: sample_26982 → programming_language = java\n",
            "[DEBUG] Sample ID: sample_41842 → programming_language = java\n",
            "[DEBUG] Sample ID: sample_27827 → programming_language = java\n",
            "[DEBUG] Sample ID: sample_32879 → programming_language = java\n",
            "[DEBUG] Sample ID: sample_49723 → programming_language = javascript\n",
            "[DEBUG] Sample ID: sample_52604 → programming_language = javascript\n",
            "[DEBUG] Sample ID: sample_54032 → programming_language = javascript\n",
            "[DEBUG] Sample ID: sample_52784 → programming_language = javascript\n",
            "[DEBUG] Sample ID: sample_53517 → programming_language = javascript\n",
            "[DEBUG] Sample ID: sample_53447 → programming_language = javascript\n",
            "[DEBUG] Sample ID: sample_51130 → programming_language = javascript\n",
            "[DEBUG] Sample ID: sample_49517 → programming_language = javascript\n",
            "[DEBUG] Sample ID: sample_52527 → programming_language = javascript\n",
            "[DEBUG] Sample ID: sample_93329 → programming_language = php\n",
            "[DEBUG] Sample ID: sample_83020 → programming_language = php\n",
            "[DEBUG] Sample ID: sample_91440 → programming_language = php\n",
            "[DEBUG] Sample ID: sample_73076 → programming_language = php\n",
            "[DEBUG] Sample ID: sample_94265 → programming_language = php\n",
            "[DEBUG] Sample ID: sample_83774 → programming_language = php\n",
            "[DEBUG] Sample ID: sample_82130 → programming_language = php\n",
            "[DEBUG] Sample ID: sample_88325 → programming_language = php\n",
            "[DEBUG] Sample ID: sample_74896 → programming_language = php\n",
            "[DEBUG] Sample ID: sample_8123 → programming_language = python\n",
            "[DEBUG] Sample ID: sample_15264 → programming_language = python\n",
            "[DEBUG] Sample ID: sample_21319 → programming_language = python\n",
            "[DEBUG] Sample ID: sample_13024 → programming_language = python\n",
            "[DEBUG] Sample ID: sample_21753 → programming_language = python\n",
            "[DEBUG] Sample ID: sample_10224 → programming_language = python\n",
            "[DEBUG] Sample ID: sample_1038 → programming_language = python\n",
            "[DEBUG] Sample ID: sample_14790 → programming_language = python\n",
            "[DEBUG] Sample ID: sample_20038 → programming_language = python\n",
            "[DEBUG] Sample ID: sample_71154 → programming_language = ruby\n",
            "[DEBUG] Sample ID: sample_71953 → programming_language = ruby\n",
            "[DEBUG] Sample ID: sample_71260 → programming_language = ruby\n",
            "[DEBUG] Sample ID: sample_70850 → programming_language = ruby\n",
            "[DEBUG] Sample ID: sample_70934 → programming_language = ruby\n",
            "[DEBUG] Sample ID: sample_71240 → programming_language = ruby\n",
            "[DEBUG] Sample ID: sample_70240 → programming_language = ruby\n",
            "[DEBUG] Sample ID: sample_70974 → programming_language = ruby\n",
            "[DEBUG] Sample ID: sample_70539 → programming_language = ruby\n",
            "  → Evaluating summaries in French...\n",
            "  Computing backtranslation-based metrics for French...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:pytorch_lightning.utilities.rank_zero:💡 Tip: For seamless cloud uploads and versioning, try installing [litmodels](https://pypi.org/project/litmodels/) to enable LitModelCheckpoint, which syncs automatically with the Lightning model registry.\n",
            "INFO:pytorch_lightning.utilities.rank_zero:GPU available: True (cuda), used: True\n",
            "INFO:pytorch_lightning.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n",
            "INFO:pytorch_lightning.utilities.rank_zero:HPU available: False, using: 0 HPUs\n",
            "INFO:pytorch_lightning.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `XLMRobertaSdpaSelfAttention.forward`.\n",
            "  return forward_call(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[DEBUG] Sample ID: sample_68262 → programming_language = go\n",
            "[DEBUG] Sample ID: sample_59144 → programming_language = go\n",
            "[DEBUG] Sample ID: sample_56854 → programming_language = go\n",
            "[DEBUG] Sample ID: sample_60736 → programming_language = go\n",
            "[DEBUG] Sample ID: sample_60808 → programming_language = go\n",
            "[DEBUG] Sample ID: sample_65047 → programming_language = go\n",
            "[DEBUG] Sample ID: sample_68705 → programming_language = go\n",
            "[DEBUG] Sample ID: sample_56245 → programming_language = go\n",
            "[DEBUG] Sample ID: sample_69232 → programming_language = go\n",
            "[DEBUG] Sample ID: sample_43225 → programming_language = java\n",
            "[DEBUG] Sample ID: sample_43881 → programming_language = java\n",
            "[DEBUG] Sample ID: sample_24461 → programming_language = java\n",
            "[DEBUG] Sample ID: sample_34565 → programming_language = java\n",
            "[DEBUG] Sample ID: sample_26644 → programming_language = java\n",
            "[DEBUG] Sample ID: sample_26982 → programming_language = java\n",
            "[DEBUG] Sample ID: sample_41842 → programming_language = java\n",
            "[DEBUG] Sample ID: sample_27827 → programming_language = java\n",
            "[DEBUG] Sample ID: sample_32879 → programming_language = java\n",
            "[DEBUG] Sample ID: sample_49723 → programming_language = javascript\n",
            "[DEBUG] Sample ID: sample_52604 → programming_language = javascript\n",
            "[DEBUG] Sample ID: sample_54032 → programming_language = javascript\n",
            "[DEBUG] Sample ID: sample_52784 → programming_language = javascript\n",
            "[DEBUG] Sample ID: sample_53517 → programming_language = javascript\n",
            "[DEBUG] Sample ID: sample_53447 → programming_language = javascript\n",
            "[DEBUG] Sample ID: sample_51130 → programming_language = javascript\n",
            "[DEBUG] Sample ID: sample_49517 → programming_language = javascript\n",
            "[DEBUG] Sample ID: sample_52527 → programming_language = javascript\n",
            "[DEBUG] Sample ID: sample_93329 → programming_language = php\n",
            "[DEBUG] Sample ID: sample_83020 → programming_language = php\n",
            "[DEBUG] Sample ID: sample_91440 → programming_language = php\n",
            "[DEBUG] Sample ID: sample_73076 → programming_language = php\n",
            "[DEBUG] Sample ID: sample_94265 → programming_language = php\n",
            "[DEBUG] Sample ID: sample_83774 → programming_language = php\n",
            "[DEBUG] Sample ID: sample_82130 → programming_language = php\n",
            "[DEBUG] Sample ID: sample_88325 → programming_language = php\n",
            "[DEBUG] Sample ID: sample_74896 → programming_language = php\n",
            "[DEBUG] Sample ID: sample_8123 → programming_language = python\n",
            "[DEBUG] Sample ID: sample_15264 → programming_language = python\n",
            "[DEBUG] Sample ID: sample_21319 → programming_language = python\n",
            "[DEBUG] Sample ID: sample_13024 → programming_language = python\n",
            "[DEBUG] Sample ID: sample_21753 → programming_language = python\n",
            "[DEBUG] Sample ID: sample_10224 → programming_language = python\n",
            "[DEBUG] Sample ID: sample_1038 → programming_language = python\n",
            "[DEBUG] Sample ID: sample_14790 → programming_language = python\n",
            "[DEBUG] Sample ID: sample_20038 → programming_language = python\n",
            "[DEBUG] Sample ID: sample_71154 → programming_language = ruby\n",
            "[DEBUG] Sample ID: sample_71953 → programming_language = ruby\n",
            "[DEBUG] Sample ID: sample_71260 → programming_language = ruby\n",
            "[DEBUG] Sample ID: sample_70850 → programming_language = ruby\n",
            "[DEBUG] Sample ID: sample_70934 → programming_language = ruby\n",
            "[DEBUG] Sample ID: sample_71240 → programming_language = ruby\n",
            "[DEBUG] Sample ID: sample_70240 → programming_language = ruby\n",
            "[DEBUG] Sample ID: sample_70974 → programming_language = ruby\n",
            "[DEBUG] Sample ID: sample_70539 → programming_language = ruby\n",
            "  → Evaluating summaries in Spanish...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask is not set and cannot be inferred from input because pad token is same as eos token. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Computing backtranslation-based metrics for Spanish...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch/_inductor/compile_fx.py:194: UserWarning: TensorFloat32 tensor cores for float32 matrix multiplication available but not enabled. Consider setting `torch.set_float32_matmul_precision('high')` for better performance.\n",
            "  warnings.warn(\n",
            "INFO:pytorch_lightning.utilities.rank_zero:💡 Tip: For seamless cloud uploads and versioning, try installing [litmodels](https://pypi.org/project/litmodels/) to enable LitModelCheckpoint, which syncs automatically with the Lightning model registry.\n",
            "INFO:pytorch_lightning.utilities.rank_zero:GPU available: True (cuda), used: True\n",
            "INFO:pytorch_lightning.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n",
            "INFO:pytorch_lightning.utilities.rank_zero:HPU available: False, using: 0 HPUs\n",
            "INFO:pytorch_lightning.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `XLMRobertaSdpaSelfAttention.forward`.\n",
            "  return forward_call(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[DEBUG] Sample ID: sample_68262 → programming_language = go\n",
            "[DEBUG] Sample ID: sample_59144 → programming_language = go\n",
            "[DEBUG] Sample ID: sample_56854 → programming_language = go\n",
            "[DEBUG] Sample ID: sample_60736 → programming_language = go\n",
            "[DEBUG] Sample ID: sample_60808 → programming_language = go\n",
            "[DEBUG] Sample ID: sample_65047 → programming_language = go\n",
            "[DEBUG] Sample ID: sample_68705 → programming_language = go\n",
            "[DEBUG] Sample ID: sample_56245 → programming_language = go\n",
            "[DEBUG] Sample ID: sample_69232 → programming_language = go\n",
            "[DEBUG] Sample ID: sample_43225 → programming_language = java\n",
            "[DEBUG] Sample ID: sample_43881 → programming_language = java\n",
            "[DEBUG] Sample ID: sample_24461 → programming_language = java\n",
            "[DEBUG] Sample ID: sample_34565 → programming_language = java\n",
            "[DEBUG] Sample ID: sample_26644 → programming_language = java\n",
            "[DEBUG] Sample ID: sample_26982 → programming_language = java\n",
            "[DEBUG] Sample ID: sample_41842 → programming_language = java\n",
            "[DEBUG] Sample ID: sample_27827 → programming_language = java\n",
            "[DEBUG] Sample ID: sample_32879 → programming_language = java\n",
            "[DEBUG] Sample ID: sample_49723 → programming_language = javascript\n",
            "[DEBUG] Sample ID: sample_52604 → programming_language = javascript\n",
            "[DEBUG] Sample ID: sample_54032 → programming_language = javascript\n",
            "[DEBUG] Sample ID: sample_52784 → programming_language = javascript\n",
            "[DEBUG] Sample ID: sample_53517 → programming_language = javascript\n",
            "[DEBUG] Sample ID: sample_53447 → programming_language = javascript\n",
            "[DEBUG] Sample ID: sample_51130 → programming_language = javascript\n",
            "[DEBUG] Sample ID: sample_49517 → programming_language = javascript\n",
            "[DEBUG] Sample ID: sample_52527 → programming_language = javascript\n",
            "[DEBUG] Sample ID: sample_93329 → programming_language = php\n",
            "[DEBUG] Sample ID: sample_83020 → programming_language = php\n",
            "[DEBUG] Sample ID: sample_91440 → programming_language = php\n",
            "[DEBUG] Sample ID: sample_73076 → programming_language = php\n",
            "[DEBUG] Sample ID: sample_94265 → programming_language = php\n",
            "[DEBUG] Sample ID: sample_83774 → programming_language = php\n",
            "[DEBUG] Sample ID: sample_82130 → programming_language = php\n",
            "[DEBUG] Sample ID: sample_88325 → programming_language = php\n",
            "[DEBUG] Sample ID: sample_74896 → programming_language = php\n",
            "[DEBUG] Sample ID: sample_8123 → programming_language = python\n",
            "[DEBUG] Sample ID: sample_15264 → programming_language = python\n",
            "[DEBUG] Sample ID: sample_21319 → programming_language = python\n",
            "[DEBUG] Sample ID: sample_13024 → programming_language = python\n",
            "[DEBUG] Sample ID: sample_21753 → programming_language = python\n",
            "[DEBUG] Sample ID: sample_10224 → programming_language = python\n",
            "[DEBUG] Sample ID: sample_1038 → programming_language = python\n",
            "[DEBUG] Sample ID: sample_14790 → programming_language = python\n",
            "[DEBUG] Sample ID: sample_20038 → programming_language = python\n",
            "[DEBUG] Sample ID: sample_71154 → programming_language = ruby\n",
            "[DEBUG] Sample ID: sample_71953 → programming_language = ruby\n",
            "[DEBUG] Sample ID: sample_71260 → programming_language = ruby\n",
            "[DEBUG] Sample ID: sample_70850 → programming_language = ruby\n",
            "[DEBUG] Sample ID: sample_70934 → programming_language = ruby\n",
            "[DEBUG] Sample ID: sample_71240 → programming_language = ruby\n",
            "[DEBUG] Sample ID: sample_70240 → programming_language = ruby\n",
            "[DEBUG] Sample ID: sample_70974 → programming_language = ruby\n",
            "[DEBUG] Sample ID: sample_70539 → programming_language = ruby\n",
            "  → Evaluating summaries in Portuguese...\n",
            "  Computing backtranslation-based metrics for Portuguese...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:pytorch_lightning.utilities.rank_zero:💡 Tip: For seamless cloud uploads and versioning, try installing [litmodels](https://pypi.org/project/litmodels/) to enable LitModelCheckpoint, which syncs automatically with the Lightning model registry.\n",
            "INFO:pytorch_lightning.utilities.rank_zero:GPU available: True (cuda), used: True\n",
            "INFO:pytorch_lightning.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n",
            "INFO:pytorch_lightning.utilities.rank_zero:HPU available: False, using: 0 HPUs\n",
            "INFO:pytorch_lightning.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `XLMRobertaSdpaSelfAttention.forward`.\n",
            "  return forward_call(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[DEBUG] Sample ID: sample_68262 → programming_language = go\n",
            "[DEBUG] Sample ID: sample_59144 → programming_language = go\n",
            "[DEBUG] Sample ID: sample_56854 → programming_language = go\n",
            "[DEBUG] Sample ID: sample_60736 → programming_language = go\n",
            "[DEBUG] Sample ID: sample_60808 → programming_language = go\n",
            "[DEBUG] Sample ID: sample_65047 → programming_language = go\n",
            "[DEBUG] Sample ID: sample_68705 → programming_language = go\n",
            "[DEBUG] Sample ID: sample_56245 → programming_language = go\n",
            "[DEBUG] Sample ID: sample_69232 → programming_language = go\n",
            "[DEBUG] Sample ID: sample_43225 → programming_language = java\n",
            "[DEBUG] Sample ID: sample_43881 → programming_language = java\n",
            "[DEBUG] Sample ID: sample_24461 → programming_language = java\n",
            "[DEBUG] Sample ID: sample_34565 → programming_language = java\n",
            "[DEBUG] Sample ID: sample_26644 → programming_language = java\n",
            "[DEBUG] Sample ID: sample_26982 → programming_language = java\n",
            "[DEBUG] Sample ID: sample_41842 → programming_language = java\n",
            "[DEBUG] Sample ID: sample_27827 → programming_language = java\n",
            "[DEBUG] Sample ID: sample_32879 → programming_language = java\n",
            "[DEBUG] Sample ID: sample_49723 → programming_language = javascript\n",
            "[DEBUG] Sample ID: sample_52604 → programming_language = javascript\n",
            "[DEBUG] Sample ID: sample_54032 → programming_language = javascript\n",
            "[DEBUG] Sample ID: sample_52784 → programming_language = javascript\n",
            "[DEBUG] Sample ID: sample_53517 → programming_language = javascript\n",
            "[DEBUG] Sample ID: sample_53447 → programming_language = javascript\n",
            "[DEBUG] Sample ID: sample_51130 → programming_language = javascript\n",
            "[DEBUG] Sample ID: sample_49517 → programming_language = javascript\n",
            "[DEBUG] Sample ID: sample_52527 → programming_language = javascript\n",
            "[DEBUG] Sample ID: sample_93329 → programming_language = php\n",
            "[DEBUG] Sample ID: sample_83020 → programming_language = php\n",
            "[DEBUG] Sample ID: sample_91440 → programming_language = php\n",
            "[DEBUG] Sample ID: sample_73076 → programming_language = php\n",
            "[DEBUG] Sample ID: sample_94265 → programming_language = php\n",
            "[DEBUG] Sample ID: sample_83774 → programming_language = php\n",
            "[DEBUG] Sample ID: sample_82130 → programming_language = php\n",
            "[DEBUG] Sample ID: sample_88325 → programming_language = php\n",
            "[DEBUG] Sample ID: sample_74896 → programming_language = php\n",
            "[DEBUG] Sample ID: sample_8123 → programming_language = python\n",
            "[DEBUG] Sample ID: sample_15264 → programming_language = python\n",
            "[DEBUG] Sample ID: sample_21319 → programming_language = python\n",
            "[DEBUG] Sample ID: sample_13024 → programming_language = python\n",
            "[DEBUG] Sample ID: sample_21753 → programming_language = python\n",
            "[DEBUG] Sample ID: sample_10224 → programming_language = python\n",
            "[DEBUG] Sample ID: sample_1038 → programming_language = python\n",
            "[DEBUG] Sample ID: sample_14790 → programming_language = python\n",
            "[DEBUG] Sample ID: sample_20038 → programming_language = python\n",
            "[DEBUG] Sample ID: sample_71154 → programming_language = ruby\n",
            "[DEBUG] Sample ID: sample_71953 → programming_language = ruby\n",
            "[DEBUG] Sample ID: sample_71260 → programming_language = ruby\n",
            "[DEBUG] Sample ID: sample_70850 → programming_language = ruby\n",
            "[DEBUG] Sample ID: sample_70934 → programming_language = ruby\n",
            "[DEBUG] Sample ID: sample_71240 → programming_language = ruby\n",
            "[DEBUG] Sample ID: sample_70240 → programming_language = ruby\n",
            "[DEBUG] Sample ID: sample_70974 → programming_language = ruby\n",
            "[DEBUG] Sample ID: sample_70539 → programming_language = ruby\n",
            "  → Evaluating summaries in Arabic...\n",
            "  Computing backtranslation-based metrics for Arabic...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:pytorch_lightning.utilities.rank_zero:💡 Tip: For seamless cloud uploads and versioning, try installing [litmodels](https://pypi.org/project/litmodels/) to enable LitModelCheckpoint, which syncs automatically with the Lightning model registry.\n",
            "INFO:pytorch_lightning.utilities.rank_zero:GPU available: True (cuda), used: True\n",
            "INFO:pytorch_lightning.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n",
            "INFO:pytorch_lightning.utilities.rank_zero:HPU available: False, using: 0 HPUs\n",
            "INFO:pytorch_lightning.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `XLMRobertaSdpaSelfAttention.forward`.\n",
            "  return forward_call(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[DEBUG] Sample ID: sample_68262 → programming_language = go\n",
            "[DEBUG] Sample ID: sample_59144 → programming_language = go\n",
            "[DEBUG] Sample ID: sample_56854 → programming_language = go\n",
            "[DEBUG] Sample ID: sample_60736 → programming_language = go\n",
            "[DEBUG] Sample ID: sample_60808 → programming_language = go\n",
            "[DEBUG] Sample ID: sample_65047 → programming_language = go\n",
            "[DEBUG] Sample ID: sample_68705 → programming_language = go\n",
            "[DEBUG] Sample ID: sample_56245 → programming_language = go\n",
            "[DEBUG] Sample ID: sample_69232 → programming_language = go\n",
            "[DEBUG] Sample ID: sample_43225 → programming_language = java\n",
            "[DEBUG] Sample ID: sample_43881 → programming_language = java\n",
            "[DEBUG] Sample ID: sample_24461 → programming_language = java\n",
            "[DEBUG] Sample ID: sample_34565 → programming_language = java\n",
            "[DEBUG] Sample ID: sample_26644 → programming_language = java\n",
            "[DEBUG] Sample ID: sample_26982 → programming_language = java\n",
            "[DEBUG] Sample ID: sample_41842 → programming_language = java\n",
            "[DEBUG] Sample ID: sample_27827 → programming_language = java\n",
            "[DEBUG] Sample ID: sample_32879 → programming_language = java\n",
            "[DEBUG] Sample ID: sample_49723 → programming_language = javascript\n",
            "[DEBUG] Sample ID: sample_52604 → programming_language = javascript\n",
            "[DEBUG] Sample ID: sample_54032 → programming_language = javascript\n",
            "[DEBUG] Sample ID: sample_52784 → programming_language = javascript\n",
            "[DEBUG] Sample ID: sample_53517 → programming_language = javascript\n",
            "[DEBUG] Sample ID: sample_53447 → programming_language = javascript\n",
            "[DEBUG] Sample ID: sample_51130 → programming_language = javascript\n",
            "[DEBUG] Sample ID: sample_49517 → programming_language = javascript\n",
            "[DEBUG] Sample ID: sample_52527 → programming_language = javascript\n",
            "[DEBUG] Sample ID: sample_93329 → programming_language = php\n",
            "[DEBUG] Sample ID: sample_83020 → programming_language = php\n",
            "[DEBUG] Sample ID: sample_91440 → programming_language = php\n",
            "[DEBUG] Sample ID: sample_73076 → programming_language = php\n",
            "[DEBUG] Sample ID: sample_94265 → programming_language = php\n",
            "[DEBUG] Sample ID: sample_83774 → programming_language = php\n",
            "[DEBUG] Sample ID: sample_82130 → programming_language = php\n",
            "[DEBUG] Sample ID: sample_88325 → programming_language = php\n",
            "[DEBUG] Sample ID: sample_74896 → programming_language = php\n",
            "[DEBUG] Sample ID: sample_8123 → programming_language = python\n",
            "[DEBUG] Sample ID: sample_15264 → programming_language = python\n",
            "[DEBUG] Sample ID: sample_21319 → programming_language = python\n",
            "[DEBUG] Sample ID: sample_13024 → programming_language = python\n",
            "[DEBUG] Sample ID: sample_21753 → programming_language = python\n",
            "[DEBUG] Sample ID: sample_10224 → programming_language = python\n",
            "[DEBUG] Sample ID: sample_1038 → programming_language = python\n",
            "[DEBUG] Sample ID: sample_14790 → programming_language = python\n",
            "[DEBUG] Sample ID: sample_20038 → programming_language = python\n",
            "[DEBUG] Sample ID: sample_71154 → programming_language = ruby\n",
            "[DEBUG] Sample ID: sample_71953 → programming_language = ruby\n",
            "[DEBUG] Sample ID: sample_71260 → programming_language = ruby\n",
            "[DEBUG] Sample ID: sample_70850 → programming_language = ruby\n",
            "[DEBUG] Sample ID: sample_70934 → programming_language = ruby\n",
            "[DEBUG] Sample ID: sample_71240 → programming_language = ruby\n",
            "[DEBUG] Sample ID: sample_70240 → programming_language = ruby\n",
            "[DEBUG] Sample ID: sample_70974 → programming_language = ruby\n",
            "[DEBUG] Sample ID: sample_70539 → programming_language = ruby\n",
            "  → Evaluating summaries in Hindi...\n",
            "  Computing backtranslation-based metrics for Hindi...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:pytorch_lightning.utilities.rank_zero:💡 Tip: For seamless cloud uploads and versioning, try installing [litmodels](https://pypi.org/project/litmodels/) to enable LitModelCheckpoint, which syncs automatically with the Lightning model registry.\n",
            "INFO:pytorch_lightning.utilities.rank_zero:GPU available: True (cuda), used: True\n",
            "INFO:pytorch_lightning.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n",
            "INFO:pytorch_lightning.utilities.rank_zero:HPU available: False, using: 0 HPUs\n",
            "INFO:pytorch_lightning.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `XLMRobertaSdpaSelfAttention.forward`.\n",
            "  return forward_call(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[DEBUG] Sample ID: sample_68262 → programming_language = go\n",
            "[DEBUG] Sample ID: sample_59144 → programming_language = go\n",
            "[DEBUG] Sample ID: sample_56854 → programming_language = go\n",
            "[DEBUG] Sample ID: sample_60736 → programming_language = go\n",
            "[DEBUG] Sample ID: sample_60808 → programming_language = go\n",
            "[DEBUG] Sample ID: sample_65047 → programming_language = go\n",
            "[DEBUG] Sample ID: sample_68705 → programming_language = go\n",
            "[DEBUG] Sample ID: sample_56245 → programming_language = go\n",
            "[DEBUG] Sample ID: sample_69232 → programming_language = go\n",
            "[DEBUG] Sample ID: sample_43225 → programming_language = java\n",
            "[DEBUG] Sample ID: sample_43881 → programming_language = java\n",
            "[DEBUG] Sample ID: sample_24461 → programming_language = java\n",
            "[DEBUG] Sample ID: sample_34565 → programming_language = java\n",
            "[DEBUG] Sample ID: sample_26644 → programming_language = java\n",
            "[DEBUG] Sample ID: sample_26982 → programming_language = java\n",
            "[DEBUG] Sample ID: sample_41842 → programming_language = java\n",
            "[DEBUG] Sample ID: sample_27827 → programming_language = java\n",
            "[DEBUG] Sample ID: sample_32879 → programming_language = java\n",
            "[DEBUG] Sample ID: sample_49723 → programming_language = javascript\n",
            "[DEBUG] Sample ID: sample_52604 → programming_language = javascript\n",
            "[DEBUG] Sample ID: sample_54032 → programming_language = javascript\n",
            "[DEBUG] Sample ID: sample_52784 → programming_language = javascript\n",
            "[DEBUG] Sample ID: sample_53517 → programming_language = javascript\n",
            "[DEBUG] Sample ID: sample_53447 → programming_language = javascript\n",
            "[DEBUG] Sample ID: sample_51130 → programming_language = javascript\n",
            "[DEBUG] Sample ID: sample_49517 → programming_language = javascript\n",
            "[DEBUG] Sample ID: sample_52527 → programming_language = javascript\n",
            "[DEBUG] Sample ID: sample_93329 → programming_language = php\n",
            "[DEBUG] Sample ID: sample_83020 → programming_language = php\n",
            "[DEBUG] Sample ID: sample_91440 → programming_language = php\n",
            "[DEBUG] Sample ID: sample_73076 → programming_language = php\n",
            "[DEBUG] Sample ID: sample_94265 → programming_language = php\n",
            "[DEBUG] Sample ID: sample_83774 → programming_language = php\n",
            "[DEBUG] Sample ID: sample_82130 → programming_language = php\n",
            "[DEBUG] Sample ID: sample_88325 → programming_language = php\n",
            "[DEBUG] Sample ID: sample_74896 → programming_language = php\n",
            "[DEBUG] Sample ID: sample_8123 → programming_language = python\n",
            "[DEBUG] Sample ID: sample_15264 → programming_language = python\n",
            "[DEBUG] Sample ID: sample_21319 → programming_language = python\n",
            "[DEBUG] Sample ID: sample_13024 → programming_language = python\n",
            "[DEBUG] Sample ID: sample_21753 → programming_language = python\n",
            "[DEBUG] Sample ID: sample_10224 → programming_language = python\n",
            "[DEBUG] Sample ID: sample_1038 → programming_language = python\n",
            "[DEBUG] Sample ID: sample_14790 → programming_language = python\n",
            "[DEBUG] Sample ID: sample_20038 → programming_language = python\n",
            "[DEBUG] Sample ID: sample_71154 → programming_language = ruby\n",
            "[DEBUG] Sample ID: sample_71953 → programming_language = ruby\n",
            "[DEBUG] Sample ID: sample_71260 → programming_language = ruby\n",
            "[DEBUG] Sample ID: sample_70850 → programming_language = ruby\n",
            "[DEBUG] Sample ID: sample_70934 → programming_language = ruby\n",
            "[DEBUG] Sample ID: sample_71240 → programming_language = ruby\n",
            "[DEBUG] Sample ID: sample_70240 → programming_language = ruby\n",
            "[DEBUG] Sample ID: sample_70974 → programming_language = ruby\n",
            "[DEBUG] Sample ID: sample_70539 → programming_language = ruby\n",
            "\n",
            "Processing file: /content/multilingual-code-summarization-eval/prompt_analysis/deepseekcoder/prompt0/all_languages_prompt0_combined_deepseek-coder-6.7b-instruct.json\n",
            "  → Evaluating summaries in Chinese...\n",
            "  Computing backtranslation-based metrics for Chinese...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:pytorch_lightning.utilities.rank_zero:💡 Tip: For seamless cloud uploads and versioning, try installing [litmodels](https://pypi.org/project/litmodels/) to enable LitModelCheckpoint, which syncs automatically with the Lightning model registry.\n",
            "INFO:pytorch_lightning.utilities.rank_zero:GPU available: True (cuda), used: True\n",
            "INFO:pytorch_lightning.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n",
            "INFO:pytorch_lightning.utilities.rank_zero:HPU available: False, using: 0 HPUs\n",
            "INFO:pytorch_lightning.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `XLMRobertaSdpaSelfAttention.forward`.\n",
            "  return forward_call(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[DEBUG] Sample ID: sample_68262 → programming_language = go\n",
            "[DEBUG] Sample ID: sample_59144 → programming_language = go\n",
            "[DEBUG] Sample ID: sample_56854 → programming_language = go\n",
            "[DEBUG] Sample ID: sample_60736 → programming_language = go\n",
            "[DEBUG] Sample ID: sample_60808 → programming_language = go\n",
            "[DEBUG] Sample ID: sample_65047 → programming_language = go\n",
            "[DEBUG] Sample ID: sample_68705 → programming_language = go\n",
            "[DEBUG] Sample ID: sample_56245 → programming_language = go\n",
            "[DEBUG] Sample ID: sample_69232 → programming_language = go\n",
            "[DEBUG] Sample ID: sample_43225 → programming_language = java\n",
            "[DEBUG] Sample ID: sample_43881 → programming_language = java\n",
            "[DEBUG] Sample ID: sample_24461 → programming_language = java\n",
            "[DEBUG] Sample ID: sample_34565 → programming_language = java\n",
            "[DEBUG] Sample ID: sample_26644 → programming_language = java\n",
            "[DEBUG] Sample ID: sample_26982 → programming_language = java\n",
            "[DEBUG] Sample ID: sample_41842 → programming_language = java\n",
            "[DEBUG] Sample ID: sample_27827 → programming_language = java\n",
            "[DEBUG] Sample ID: sample_32879 → programming_language = java\n",
            "[DEBUG] Sample ID: sample_49723 → programming_language = javascript\n",
            "[DEBUG] Sample ID: sample_52604 → programming_language = javascript\n",
            "[DEBUG] Sample ID: sample_54032 → programming_language = javascript\n",
            "[DEBUG] Sample ID: sample_52784 → programming_language = javascript\n",
            "[DEBUG] Sample ID: sample_53517 → programming_language = javascript\n",
            "[DEBUG] Sample ID: sample_53447 → programming_language = javascript\n",
            "[DEBUG] Sample ID: sample_51130 → programming_language = javascript\n",
            "[DEBUG] Sample ID: sample_49517 → programming_language = javascript\n",
            "[DEBUG] Sample ID: sample_52527 → programming_language = javascript\n",
            "[DEBUG] Sample ID: sample_93329 → programming_language = php\n",
            "[DEBUG] Sample ID: sample_83020 → programming_language = php\n",
            "[DEBUG] Sample ID: sample_91440 → programming_language = php\n",
            "[DEBUG] Sample ID: sample_73076 → programming_language = php\n",
            "[DEBUG] Sample ID: sample_94265 → programming_language = php\n",
            "[DEBUG] Sample ID: sample_83774 → programming_language = php\n",
            "[DEBUG] Sample ID: sample_82130 → programming_language = php\n",
            "[DEBUG] Sample ID: sample_88325 → programming_language = php\n",
            "[DEBUG] Sample ID: sample_74896 → programming_language = php\n",
            "[DEBUG] Sample ID: sample_8123 → programming_language = python\n",
            "[DEBUG] Sample ID: sample_15264 → programming_language = python\n",
            "[DEBUG] Sample ID: sample_21319 → programming_language = python\n",
            "[DEBUG] Sample ID: sample_13024 → programming_language = python\n",
            "[DEBUG] Sample ID: sample_21753 → programming_language = python\n",
            "[DEBUG] Sample ID: sample_10224 → programming_language = python\n",
            "[DEBUG] Sample ID: sample_1038 → programming_language = python\n",
            "[DEBUG] Sample ID: sample_14790 → programming_language = python\n",
            "[DEBUG] Sample ID: sample_20038 → programming_language = python\n",
            "[DEBUG] Sample ID: sample_71154 → programming_language = ruby\n",
            "[DEBUG] Sample ID: sample_71953 → programming_language = ruby\n",
            "[DEBUG] Sample ID: sample_71260 → programming_language = ruby\n",
            "[DEBUG] Sample ID: sample_70850 → programming_language = ruby\n",
            "[DEBUG] Sample ID: sample_70934 → programming_language = ruby\n",
            "[DEBUG] Sample ID: sample_71240 → programming_language = ruby\n",
            "[DEBUG] Sample ID: sample_70240 → programming_language = ruby\n",
            "[DEBUG] Sample ID: sample_70974 → programming_language = ruby\n",
            "[DEBUG] Sample ID: sample_70539 → programming_language = ruby\n",
            "  → Evaluating summaries in French...\n",
            "  Computing backtranslation-based metrics for French...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:pytorch_lightning.utilities.rank_zero:💡 Tip: For seamless cloud uploads and versioning, try installing [litmodels](https://pypi.org/project/litmodels/) to enable LitModelCheckpoint, which syncs automatically with the Lightning model registry.\n",
            "INFO:pytorch_lightning.utilities.rank_zero:GPU available: True (cuda), used: True\n",
            "INFO:pytorch_lightning.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n",
            "INFO:pytorch_lightning.utilities.rank_zero:HPU available: False, using: 0 HPUs\n",
            "INFO:pytorch_lightning.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `XLMRobertaSdpaSelfAttention.forward`.\n",
            "  return forward_call(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[DEBUG] Sample ID: sample_68262 → programming_language = go\n",
            "[DEBUG] Sample ID: sample_59144 → programming_language = go\n",
            "[DEBUG] Sample ID: sample_56854 → programming_language = go\n",
            "[DEBUG] Sample ID: sample_60736 → programming_language = go\n",
            "[DEBUG] Sample ID: sample_60808 → programming_language = go\n",
            "[DEBUG] Sample ID: sample_65047 → programming_language = go\n",
            "[DEBUG] Sample ID: sample_68705 → programming_language = go\n",
            "[DEBUG] Sample ID: sample_56245 → programming_language = go\n",
            "[DEBUG] Sample ID: sample_69232 → programming_language = go\n",
            "[DEBUG] Sample ID: sample_43225 → programming_language = java\n",
            "[DEBUG] Sample ID: sample_43881 → programming_language = java\n",
            "[DEBUG] Sample ID: sample_24461 → programming_language = java\n",
            "[DEBUG] Sample ID: sample_34565 → programming_language = java\n",
            "[DEBUG] Sample ID: sample_26644 → programming_language = java\n",
            "[DEBUG] Sample ID: sample_26982 → programming_language = java\n",
            "[DEBUG] Sample ID: sample_41842 → programming_language = java\n",
            "[DEBUG] Sample ID: sample_27827 → programming_language = java\n",
            "[DEBUG] Sample ID: sample_32879 → programming_language = java\n",
            "[DEBUG] Sample ID: sample_49723 → programming_language = javascript\n",
            "[DEBUG] Sample ID: sample_52604 → programming_language = javascript\n",
            "[DEBUG] Sample ID: sample_54032 → programming_language = javascript\n",
            "[DEBUG] Sample ID: sample_52784 → programming_language = javascript\n",
            "[DEBUG] Sample ID: sample_53517 → programming_language = javascript\n",
            "[DEBUG] Sample ID: sample_53447 → programming_language = javascript\n",
            "[DEBUG] Sample ID: sample_51130 → programming_language = javascript\n",
            "[DEBUG] Sample ID: sample_49517 → programming_language = javascript\n",
            "[DEBUG] Sample ID: sample_52527 → programming_language = javascript\n",
            "[DEBUG] Sample ID: sample_93329 → programming_language = php\n",
            "[DEBUG] Sample ID: sample_83020 → programming_language = php\n",
            "[DEBUG] Sample ID: sample_91440 → programming_language = php\n",
            "[DEBUG] Sample ID: sample_73076 → programming_language = php\n",
            "[DEBUG] Sample ID: sample_94265 → programming_language = php\n",
            "[DEBUG] Sample ID: sample_83774 → programming_language = php\n",
            "[DEBUG] Sample ID: sample_82130 → programming_language = php\n",
            "[DEBUG] Sample ID: sample_88325 → programming_language = php\n",
            "[DEBUG] Sample ID: sample_74896 → programming_language = php\n",
            "[DEBUG] Sample ID: sample_8123 → programming_language = python\n",
            "[DEBUG] Sample ID: sample_15264 → programming_language = python\n",
            "[DEBUG] Sample ID: sample_21319 → programming_language = python\n",
            "[DEBUG] Sample ID: sample_13024 → programming_language = python\n",
            "[DEBUG] Sample ID: sample_21753 → programming_language = python\n",
            "[DEBUG] Sample ID: sample_10224 → programming_language = python\n",
            "[DEBUG] Sample ID: sample_1038 → programming_language = python\n",
            "[DEBUG] Sample ID: sample_14790 → programming_language = python\n",
            "[DEBUG] Sample ID: sample_20038 → programming_language = python\n",
            "[DEBUG] Sample ID: sample_71154 → programming_language = ruby\n",
            "[DEBUG] Sample ID: sample_71953 → programming_language = ruby\n",
            "[DEBUG] Sample ID: sample_71260 → programming_language = ruby\n",
            "[DEBUG] Sample ID: sample_70850 → programming_language = ruby\n",
            "[DEBUG] Sample ID: sample_70934 → programming_language = ruby\n",
            "[DEBUG] Sample ID: sample_71240 → programming_language = ruby\n",
            "[DEBUG] Sample ID: sample_70240 → programming_language = ruby\n",
            "[DEBUG] Sample ID: sample_70974 → programming_language = ruby\n",
            "[DEBUG] Sample ID: sample_70539 → programming_language = ruby\n",
            "  → Evaluating summaries in Spanish...\n",
            "  Computing backtranslation-based metrics for Spanish...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:pytorch_lightning.utilities.rank_zero:💡 Tip: For seamless cloud uploads and versioning, try installing [litmodels](https://pypi.org/project/litmodels/) to enable LitModelCheckpoint, which syncs automatically with the Lightning model registry.\n",
            "INFO:pytorch_lightning.utilities.rank_zero:GPU available: True (cuda), used: True\n",
            "INFO:pytorch_lightning.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n",
            "INFO:pytorch_lightning.utilities.rank_zero:HPU available: False, using: 0 HPUs\n",
            "INFO:pytorch_lightning.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `XLMRobertaSdpaSelfAttention.forward`.\n",
            "  return forward_call(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[DEBUG] Sample ID: sample_68262 → programming_language = go\n",
            "[DEBUG] Sample ID: sample_59144 → programming_language = go\n",
            "[DEBUG] Sample ID: sample_56854 → programming_language = go\n",
            "[DEBUG] Sample ID: sample_60736 → programming_language = go\n",
            "[DEBUG] Sample ID: sample_60808 → programming_language = go\n",
            "[DEBUG] Sample ID: sample_65047 → programming_language = go\n",
            "[DEBUG] Sample ID: sample_68705 → programming_language = go\n",
            "[DEBUG] Sample ID: sample_56245 → programming_language = go\n",
            "[DEBUG] Sample ID: sample_69232 → programming_language = go\n",
            "[DEBUG] Sample ID: sample_43225 → programming_language = java\n",
            "[DEBUG] Sample ID: sample_43881 → programming_language = java\n",
            "[DEBUG] Sample ID: sample_24461 → programming_language = java\n",
            "[DEBUG] Sample ID: sample_34565 → programming_language = java\n",
            "[DEBUG] Sample ID: sample_26644 → programming_language = java\n",
            "[DEBUG] Sample ID: sample_26982 → programming_language = java\n",
            "[DEBUG] Sample ID: sample_41842 → programming_language = java\n",
            "[DEBUG] Sample ID: sample_27827 → programming_language = java\n",
            "[DEBUG] Sample ID: sample_32879 → programming_language = java\n",
            "[DEBUG] Sample ID: sample_49723 → programming_language = javascript\n",
            "[DEBUG] Sample ID: sample_52604 → programming_language = javascript\n",
            "[DEBUG] Sample ID: sample_54032 → programming_language = javascript\n",
            "[DEBUG] Sample ID: sample_52784 → programming_language = javascript\n",
            "[DEBUG] Sample ID: sample_53517 → programming_language = javascript\n",
            "[DEBUG] Sample ID: sample_53447 → programming_language = javascript\n",
            "[DEBUG] Sample ID: sample_51130 → programming_language = javascript\n",
            "[DEBUG] Sample ID: sample_49517 → programming_language = javascript\n",
            "[DEBUG] Sample ID: sample_52527 → programming_language = javascript\n",
            "[DEBUG] Sample ID: sample_93329 → programming_language = php\n",
            "[DEBUG] Sample ID: sample_83020 → programming_language = php\n",
            "[DEBUG] Sample ID: sample_91440 → programming_language = php\n",
            "[DEBUG] Sample ID: sample_73076 → programming_language = php\n",
            "[DEBUG] Sample ID: sample_94265 → programming_language = php\n",
            "[DEBUG] Sample ID: sample_83774 → programming_language = php\n",
            "[DEBUG] Sample ID: sample_82130 → programming_language = php\n",
            "[DEBUG] Sample ID: sample_88325 → programming_language = php\n",
            "[DEBUG] Sample ID: sample_74896 → programming_language = php\n",
            "[DEBUG] Sample ID: sample_8123 → programming_language = python\n",
            "[DEBUG] Sample ID: sample_15264 → programming_language = python\n",
            "[DEBUG] Sample ID: sample_21319 → programming_language = python\n",
            "[DEBUG] Sample ID: sample_13024 → programming_language = python\n",
            "[DEBUG] Sample ID: sample_21753 → programming_language = python\n",
            "[DEBUG] Sample ID: sample_10224 → programming_language = python\n",
            "[DEBUG] Sample ID: sample_1038 → programming_language = python\n",
            "[DEBUG] Sample ID: sample_14790 → programming_language = python\n",
            "[DEBUG] Sample ID: sample_20038 → programming_language = python\n",
            "[DEBUG] Sample ID: sample_71154 → programming_language = ruby\n",
            "[DEBUG] Sample ID: sample_71953 → programming_language = ruby\n",
            "[DEBUG] Sample ID: sample_71260 → programming_language = ruby\n",
            "[DEBUG] Sample ID: sample_70850 → programming_language = ruby\n",
            "[DEBUG] Sample ID: sample_70934 → programming_language = ruby\n",
            "[DEBUG] Sample ID: sample_71240 → programming_language = ruby\n",
            "[DEBUG] Sample ID: sample_70240 → programming_language = ruby\n",
            "[DEBUG] Sample ID: sample_70974 → programming_language = ruby\n",
            "[DEBUG] Sample ID: sample_70539 → programming_language = ruby\n",
            "  → Evaluating summaries in Portuguese...\n",
            "  Computing backtranslation-based metrics for Portuguese...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:pytorch_lightning.utilities.rank_zero:💡 Tip: For seamless cloud uploads and versioning, try installing [litmodels](https://pypi.org/project/litmodels/) to enable LitModelCheckpoint, which syncs automatically with the Lightning model registry.\n",
            "INFO:pytorch_lightning.utilities.rank_zero:GPU available: True (cuda), used: True\n",
            "INFO:pytorch_lightning.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n",
            "INFO:pytorch_lightning.utilities.rank_zero:HPU available: False, using: 0 HPUs\n",
            "INFO:pytorch_lightning.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `XLMRobertaSdpaSelfAttention.forward`.\n",
            "  return forward_call(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[DEBUG] Sample ID: sample_68262 → programming_language = go\n",
            "[DEBUG] Sample ID: sample_59144 → programming_language = go\n",
            "[DEBUG] Sample ID: sample_56854 → programming_language = go\n",
            "[DEBUG] Sample ID: sample_60736 → programming_language = go\n",
            "[DEBUG] Sample ID: sample_60808 → programming_language = go\n",
            "[DEBUG] Sample ID: sample_65047 → programming_language = go\n",
            "[DEBUG] Sample ID: sample_68705 → programming_language = go\n",
            "[DEBUG] Sample ID: sample_56245 → programming_language = go\n",
            "[DEBUG] Sample ID: sample_69232 → programming_language = go\n",
            "[DEBUG] Sample ID: sample_43225 → programming_language = java\n",
            "[DEBUG] Sample ID: sample_43881 → programming_language = java\n",
            "[DEBUG] Sample ID: sample_24461 → programming_language = java\n",
            "[DEBUG] Sample ID: sample_34565 → programming_language = java\n",
            "[DEBUG] Sample ID: sample_26644 → programming_language = java\n",
            "[DEBUG] Sample ID: sample_26982 → programming_language = java\n",
            "[DEBUG] Sample ID: sample_41842 → programming_language = java\n",
            "[DEBUG] Sample ID: sample_27827 → programming_language = java\n",
            "[DEBUG] Sample ID: sample_32879 → programming_language = java\n",
            "[DEBUG] Sample ID: sample_49723 → programming_language = javascript\n",
            "[DEBUG] Sample ID: sample_52604 → programming_language = javascript\n",
            "[DEBUG] Sample ID: sample_54032 → programming_language = javascript\n",
            "[DEBUG] Sample ID: sample_52784 → programming_language = javascript\n",
            "[DEBUG] Sample ID: sample_53517 → programming_language = javascript\n",
            "[DEBUG] Sample ID: sample_53447 → programming_language = javascript\n",
            "[DEBUG] Sample ID: sample_51130 → programming_language = javascript\n",
            "[DEBUG] Sample ID: sample_49517 → programming_language = javascript\n",
            "[DEBUG] Sample ID: sample_52527 → programming_language = javascript\n",
            "[DEBUG] Sample ID: sample_93329 → programming_language = php\n",
            "[DEBUG] Sample ID: sample_83020 → programming_language = php\n",
            "[DEBUG] Sample ID: sample_91440 → programming_language = php\n",
            "[DEBUG] Sample ID: sample_73076 → programming_language = php\n",
            "[DEBUG] Sample ID: sample_94265 → programming_language = php\n",
            "[DEBUG] Sample ID: sample_83774 → programming_language = php\n",
            "[DEBUG] Sample ID: sample_82130 → programming_language = php\n",
            "[DEBUG] Sample ID: sample_88325 → programming_language = php\n",
            "[DEBUG] Sample ID: sample_74896 → programming_language = php\n",
            "[DEBUG] Sample ID: sample_8123 → programming_language = python\n",
            "[DEBUG] Sample ID: sample_15264 → programming_language = python\n",
            "[DEBUG] Sample ID: sample_21319 → programming_language = python\n",
            "[DEBUG] Sample ID: sample_13024 → programming_language = python\n",
            "[DEBUG] Sample ID: sample_21753 → programming_language = python\n",
            "[DEBUG] Sample ID: sample_10224 → programming_language = python\n",
            "[DEBUG] Sample ID: sample_1038 → programming_language = python\n",
            "[DEBUG] Sample ID: sample_14790 → programming_language = python\n",
            "[DEBUG] Sample ID: sample_20038 → programming_language = python\n",
            "[DEBUG] Sample ID: sample_71154 → programming_language = ruby\n",
            "[DEBUG] Sample ID: sample_71953 → programming_language = ruby\n",
            "[DEBUG] Sample ID: sample_71260 → programming_language = ruby\n",
            "[DEBUG] Sample ID: sample_70850 → programming_language = ruby\n",
            "[DEBUG] Sample ID: sample_70934 → programming_language = ruby\n",
            "[DEBUG] Sample ID: sample_71240 → programming_language = ruby\n",
            "[DEBUG] Sample ID: sample_70240 → programming_language = ruby\n",
            "[DEBUG] Sample ID: sample_70974 → programming_language = ruby\n",
            "[DEBUG] Sample ID: sample_70539 → programming_language = ruby\n",
            "  → Evaluating summaries in Arabic...\n",
            "  Computing backtranslation-based metrics for Arabic...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:pytorch_lightning.utilities.rank_zero:💡 Tip: For seamless cloud uploads and versioning, try installing [litmodels](https://pypi.org/project/litmodels/) to enable LitModelCheckpoint, which syncs automatically with the Lightning model registry.\n",
            "INFO:pytorch_lightning.utilities.rank_zero:GPU available: True (cuda), used: True\n",
            "INFO:pytorch_lightning.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n",
            "INFO:pytorch_lightning.utilities.rank_zero:HPU available: False, using: 0 HPUs\n",
            "INFO:pytorch_lightning.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `XLMRobertaSdpaSelfAttention.forward`.\n",
            "  return forward_call(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[DEBUG] Sample ID: sample_68262 → programming_language = go\n",
            "[DEBUG] Sample ID: sample_59144 → programming_language = go\n",
            "[DEBUG] Sample ID: sample_56854 → programming_language = go\n",
            "[DEBUG] Sample ID: sample_60736 → programming_language = go\n",
            "[DEBUG] Sample ID: sample_60808 → programming_language = go\n",
            "[DEBUG] Sample ID: sample_65047 → programming_language = go\n",
            "[DEBUG] Sample ID: sample_68705 → programming_language = go\n",
            "[DEBUG] Sample ID: sample_56245 → programming_language = go\n",
            "[DEBUG] Sample ID: sample_69232 → programming_language = go\n",
            "[DEBUG] Sample ID: sample_43225 → programming_language = java\n",
            "[DEBUG] Sample ID: sample_43881 → programming_language = java\n",
            "[DEBUG] Sample ID: sample_24461 → programming_language = java\n",
            "[DEBUG] Sample ID: sample_34565 → programming_language = java\n",
            "[DEBUG] Sample ID: sample_26644 → programming_language = java\n",
            "[DEBUG] Sample ID: sample_26982 → programming_language = java\n",
            "[DEBUG] Sample ID: sample_41842 → programming_language = java\n",
            "[DEBUG] Sample ID: sample_27827 → programming_language = java\n",
            "[DEBUG] Sample ID: sample_32879 → programming_language = java\n",
            "[DEBUG] Sample ID: sample_49723 → programming_language = javascript\n",
            "[DEBUG] Sample ID: sample_52604 → programming_language = javascript\n",
            "[DEBUG] Sample ID: sample_54032 → programming_language = javascript\n",
            "[DEBUG] Sample ID: sample_52784 → programming_language = javascript\n",
            "[DEBUG] Sample ID: sample_53517 → programming_language = javascript\n",
            "[DEBUG] Sample ID: sample_53447 → programming_language = javascript\n",
            "[DEBUG] Sample ID: sample_51130 → programming_language = javascript\n",
            "[DEBUG] Sample ID: sample_49517 → programming_language = javascript\n",
            "[DEBUG] Sample ID: sample_52527 → programming_language = javascript\n",
            "[DEBUG] Sample ID: sample_93329 → programming_language = php\n",
            "[DEBUG] Sample ID: sample_83020 → programming_language = php\n",
            "[DEBUG] Sample ID: sample_91440 → programming_language = php\n",
            "[DEBUG] Sample ID: sample_73076 → programming_language = php\n",
            "[DEBUG] Sample ID: sample_94265 → programming_language = php\n",
            "[DEBUG] Sample ID: sample_83774 → programming_language = php\n",
            "[DEBUG] Sample ID: sample_82130 → programming_language = php\n",
            "[DEBUG] Sample ID: sample_88325 → programming_language = php\n",
            "[DEBUG] Sample ID: sample_74896 → programming_language = php\n",
            "[DEBUG] Sample ID: sample_8123 → programming_language = python\n",
            "[DEBUG] Sample ID: sample_15264 → programming_language = python\n",
            "[DEBUG] Sample ID: sample_21319 → programming_language = python\n",
            "[DEBUG] Sample ID: sample_13024 → programming_language = python\n",
            "[DEBUG] Sample ID: sample_21753 → programming_language = python\n",
            "[DEBUG] Sample ID: sample_10224 → programming_language = python\n",
            "[DEBUG] Sample ID: sample_1038 → programming_language = python\n",
            "[DEBUG] Sample ID: sample_14790 → programming_language = python\n",
            "[DEBUG] Sample ID: sample_20038 → programming_language = python\n",
            "[DEBUG] Sample ID: sample_71154 → programming_language = ruby\n",
            "[DEBUG] Sample ID: sample_71953 → programming_language = ruby\n",
            "[DEBUG] Sample ID: sample_71260 → programming_language = ruby\n",
            "[DEBUG] Sample ID: sample_70850 → programming_language = ruby\n",
            "[DEBUG] Sample ID: sample_70934 → programming_language = ruby\n",
            "[DEBUG] Sample ID: sample_71240 → programming_language = ruby\n",
            "[DEBUG] Sample ID: sample_70240 → programming_language = ruby\n",
            "[DEBUG] Sample ID: sample_70974 → programming_language = ruby\n",
            "[DEBUG] Sample ID: sample_70539 → programming_language = ruby\n",
            "  → Evaluating summaries in Hindi...\n",
            "  Computing backtranslation-based metrics for Hindi...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:pytorch_lightning.utilities.rank_zero:💡 Tip: For seamless cloud uploads and versioning, try installing [litmodels](https://pypi.org/project/litmodels/) to enable LitModelCheckpoint, which syncs automatically with the Lightning model registry.\n",
            "INFO:pytorch_lightning.utilities.rank_zero:GPU available: True (cuda), used: True\n",
            "INFO:pytorch_lightning.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n",
            "INFO:pytorch_lightning.utilities.rank_zero:HPU available: False, using: 0 HPUs\n",
            "INFO:pytorch_lightning.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `XLMRobertaSdpaSelfAttention.forward`.\n",
            "  return forward_call(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[DEBUG] Sample ID: sample_68262 → programming_language = go\n",
            "[DEBUG] Sample ID: sample_59144 → programming_language = go\n",
            "[DEBUG] Sample ID: sample_56854 → programming_language = go\n",
            "[DEBUG] Sample ID: sample_60736 → programming_language = go\n",
            "[DEBUG] Sample ID: sample_60808 → programming_language = go\n",
            "[DEBUG] Sample ID: sample_65047 → programming_language = go\n",
            "[DEBUG] Sample ID: sample_68705 → programming_language = go\n",
            "[DEBUG] Sample ID: sample_56245 → programming_language = go\n",
            "[DEBUG] Sample ID: sample_69232 → programming_language = go\n",
            "[DEBUG] Sample ID: sample_43225 → programming_language = java\n",
            "[DEBUG] Sample ID: sample_43881 → programming_language = java\n",
            "[DEBUG] Sample ID: sample_24461 → programming_language = java\n",
            "[DEBUG] Sample ID: sample_34565 → programming_language = java\n",
            "[DEBUG] Sample ID: sample_26644 → programming_language = java\n",
            "[DEBUG] Sample ID: sample_26982 → programming_language = java\n",
            "[DEBUG] Sample ID: sample_41842 → programming_language = java\n",
            "[DEBUG] Sample ID: sample_27827 → programming_language = java\n",
            "[DEBUG] Sample ID: sample_32879 → programming_language = java\n",
            "[DEBUG] Sample ID: sample_49723 → programming_language = javascript\n",
            "[DEBUG] Sample ID: sample_52604 → programming_language = javascript\n",
            "[DEBUG] Sample ID: sample_54032 → programming_language = javascript\n",
            "[DEBUG] Sample ID: sample_52784 → programming_language = javascript\n",
            "[DEBUG] Sample ID: sample_53517 → programming_language = javascript\n",
            "[DEBUG] Sample ID: sample_53447 → programming_language = javascript\n",
            "[DEBUG] Sample ID: sample_51130 → programming_language = javascript\n",
            "[DEBUG] Sample ID: sample_49517 → programming_language = javascript\n",
            "[DEBUG] Sample ID: sample_52527 → programming_language = javascript\n",
            "[DEBUG] Sample ID: sample_93329 → programming_language = php\n",
            "[DEBUG] Sample ID: sample_83020 → programming_language = php\n",
            "[DEBUG] Sample ID: sample_91440 → programming_language = php\n",
            "[DEBUG] Sample ID: sample_73076 → programming_language = php\n",
            "[DEBUG] Sample ID: sample_94265 → programming_language = php\n",
            "[DEBUG] Sample ID: sample_83774 → programming_language = php\n",
            "[DEBUG] Sample ID: sample_82130 → programming_language = php\n",
            "[DEBUG] Sample ID: sample_88325 → programming_language = php\n",
            "[DEBUG] Sample ID: sample_74896 → programming_language = php\n",
            "[DEBUG] Sample ID: sample_8123 → programming_language = python\n",
            "[DEBUG] Sample ID: sample_15264 → programming_language = python\n",
            "[DEBUG] Sample ID: sample_21319 → programming_language = python\n",
            "[DEBUG] Sample ID: sample_13024 → programming_language = python\n",
            "[DEBUG] Sample ID: sample_21753 → programming_language = python\n",
            "[DEBUG] Sample ID: sample_10224 → programming_language = python\n",
            "[DEBUG] Sample ID: sample_1038 → programming_language = python\n",
            "[DEBUG] Sample ID: sample_14790 → programming_language = python\n",
            "[DEBUG] Sample ID: sample_20038 → programming_language = python\n",
            "[DEBUG] Sample ID: sample_71154 → programming_language = ruby\n",
            "[DEBUG] Sample ID: sample_71953 → programming_language = ruby\n",
            "[DEBUG] Sample ID: sample_71260 → programming_language = ruby\n",
            "[DEBUG] Sample ID: sample_70850 → programming_language = ruby\n",
            "[DEBUG] Sample ID: sample_70934 → programming_language = ruby\n",
            "[DEBUG] Sample ID: sample_71240 → programming_language = ruby\n",
            "[DEBUG] Sample ID: sample_70240 → programming_language = ruby\n",
            "[DEBUG] Sample ID: sample_70974 → programming_language = ruby\n",
            "[DEBUG] Sample ID: sample_70539 → programming_language = ruby\n",
            "\n",
            "Saved results to:\n",
            "  JSON: backtranslations_cache/new_all_scores_bt_gemmax2-9b.json\n",
            "  CSV:  backtranslations_cache/new_all_scores_bt_gemmax2-9b.csv\n"
          ]
        }
      ],
      "execution_count": 17
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "\n",
        "# Paths to the generated files\n",
        "json_out = os.path.join(backtranslation_dir, f\"new_all_scores_bt_{bt_model_tag}.json\")\n",
        "csv_out = os.path.join(backtranslation_dir, f\"new_all_scores_bt_{bt_model_tag}.csv\")\n",
        "\n",
        "# Download the files\n",
        "files.download(json_out)\n",
        "files.download(csv_out)\n"
      ],
      "metadata": {
        "id": "18C0EjtvqxKx",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "b96ed68e-49a0-4209-ea8c-a77a6bc5296f"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_1c49805b-48d1-460b-b472-9889d5147765\", \"new_all_scores_bt_gemmax2-9b.json\", 3533756)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_c44a074d-ca36-41ad-89e2-2e08a5183f8a\", \"new_all_scores_bt_gemmax2-9b.csv\", 2757730)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "SDlQwkUYqr3h"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}